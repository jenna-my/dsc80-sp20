{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DSC 80: Lab 01\n",
    "\n",
    "### Due Date: Tuesday April 07, Midnight (11:59 PM)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Zoom Lab Hours\n",
    "- Follow instructions on this link: https://docs.google.com/document/d/16qZpPSYhxwQDMcn-lGQjC-J-PzppLevv_mANLt2ko8g/edit "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Instructions\n",
    "Much like in DSC 10, this Jupyter Notebook contains the statements of the problems and provides code and markdown cells to display your answers to the problems. Unlike DSC 10, the notebook is *only* for displaying a readable version of your final answers. The coding work will be developed in an accompanying `lab01.py` file, that will be imported into the current notebook.\n",
    "\n",
    "Labs and programming assignments will be graded in (at most) two ways:\n",
    "1. The functions and classes in the accompanying python file will be tested (a la DSC 20),\n",
    "2. The notebook will be graded (for graphs and free response questions).\n",
    "\n",
    "**Do not change the function names in the `*.py` file**\n",
    "- The functions in the `*.py` file are how your assignment is graded, and they are graded by their name. The dictionary at the end of the file (`GRADED FUNCTIONS`) contains the \"grading list\". The final function in the file allows your doctests to check that all the necessary functions exist.\n",
    "- If you changed something you weren't supposed to, just use git to revert!\n",
    "\n",
    "**Tips for working in the Notebook**:\n",
    "- The notebooks serve to present you the questions and give you a place to present your results for later review.\n",
    "- The notebook on *lab assignments* are not graded (only the `.py` file).\n",
    "- Notebooks for PAs will serve as a final report for the assignment, and contain conclusions and answers to open ended questions that are graded.\n",
    "- The notebook serves as a nice environment for 'pre-development' and experimentation before designing your function in your `.py` file.\n",
    "\n",
    "**Tips for developing in the .py file**:\n",
    "- Do not change the function names in the starter code; grading is done using these function names.\n",
    "- Do not change the docstrings in the functions. These are there to tell you if your work is on the right track!\n",
    "- You are encouraged to write your own additional functions to solve the lab! \n",
    "    - Developing in python usually consists of larger files, with many short functions.\n",
    "    - You may write your other functions in an additional `.py` file that you import in `lab01.py` (much like we do in the notebook).\n",
    "- Always document your code!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Importing code from `lab**.py`\n",
    "\n",
    "* We import our `.py` file that's contained in the same directory as this notebook.\n",
    "* We use the `autoreload` notebook extension to make changes to our `lab**.py` file immediately available in our notebook. Without this extension, we would need to restart the notebook kernel to see any changes to `lab**.py` in the notebook.\n",
    "    - `autoreload` is necessary because, upon import, `lab**.py` is compiled to bytecode (in the directory `__pycache__`). Subsequent imports of `lab**` merely import the existing compiled python."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 532,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 533,
   "metadata": {},
   "outputs": [],
   "source": [
    "import lab01 as lab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 534,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Python Basics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "**Question 0 (EXAMPLE):**\n",
    "\n",
    "Write a function that takes in a possibly empty list of integers and:\n",
    "* Returns `True` if there exist two adjacent list elements that are consecutive integers.\n",
    "* Otherwise, returns `False`.\n",
    "\n",
    "For example, because `9` is next to `8`:\n",
    "```\n",
    ">>> lab.consecutive_ints([5,3,6,4,9,8])\n",
    "True\n",
    "```\n",
    "Whereas:\n",
    "```\n",
    ">>> lab.consecutive_ints([1,3,5,7,9])\n",
    "False\n",
    "```\n",
    "\n",
    "*Note*: This question is done for you, to demonstrate a completed homework problem."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Develop your code here (or in an IDE) if you'd like.\n",
    "# Though only code in lab01.py will be graded!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add more cells if you'd like!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Test your code in two ways:\n",
    "1. Run the cell below to test your code. You should also copy the cell and change the input to test further (i.e. write your own doctests)! Does it work for corner cases? Real-world data is **very messy** and you should expect your data processing code to break without thorough testing!\n",
    "2. Run doctests on `lab01.py` by running the following command on the commandline:\n",
    "```\n",
    "python -m doctest lab01.py\n",
    "```\n",
    "If the doctests pass, then there should be *no* output."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# test your code!\n",
    "lab.consecutive_ints([1,3,2,4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lab.consecutive_ints([0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lab.consecutive_ints([])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "**Question 1 (median):**\n",
    "\n",
    "Write a function called *median* that takes a non-empty list of numbers, returning the median element of the list. If the list has even length, it should return the mean of the two elements in the middle. Do not use any imported libraries for this question; you may use any built-in function.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "def median(nums):\n",
    "    #sort in ascending order\n",
    "    nums.sort()\n",
    "    \n",
    "    if len(nums) % 2 == 0: #if list has even length\n",
    "        elem1 = nums[(len(nums) // 2) - 1]\n",
    "        elem2 = nums[len(nums) // 2]\n",
    "        return (elem1 + elem2) / 2\n",
    "    else: \n",
    "        return nums[len(nums) // 2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3.5"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lst = [1, 2, 3, 4, 5, 6]\n",
    "\n",
    "median(lst)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Try this\n",
    "lab.median([0, -1, 1, 100])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "**Question 2 (List Distances):**\n",
    "\n",
    "Similar to Question 0, write a function that takes in a possibly empty list of integers and:\n",
    "* Returns `True` if there exist two list elements $i$ places apart, whose distance as integers is also $i$.\n",
    "* Otherwise, returns `False`.\n",
    "\n",
    "Assume your inputs tend to satisfy the condition, and the pair(s) saitifying the condition tend to be close together; design your function to run faster for this case. (Optimizing your code for an assumed distribution of incoming data is very common in data science).\n",
    "\n",
    "For example, because `3` and (the second) `5` are two places apart, and $|3-5| = 2$:\n",
    "```\n",
    ">>> lab.same_diff_ints([5,3,1,5,9,8])\n",
    "True\n",
    "```\n",
    "Whereas:\n",
    "```\n",
    ">>> lab.same_diff_ints([1,3,5,7,9])\n",
    "False\n",
    "```\n",
    "\n",
    "*Note*: Make sure to define some extreme test cases. Use the `%time` command to time your function!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "def same_diff_ints(ints):\n",
    "    if len(ints) == 0:\n",
    "        return False\n",
    "    for i in range(1, len(ints)): #represent num of places apart\n",
    "        for j in range(len(ints)): #iterate through each element in list\n",
    "            if j + i >= len(ints): #no more elems to look at for this iteration \n",
    "                break\n",
    "            elif abs(ints[j] - ints[j + i]) == i: #equal places and distances\n",
    "                return True\n",
    "    return False "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [],
   "source": [
    "lst1 = [5,3,1,5,9,8]\n",
    "lst2 = [0,5,5,100,2,6]\n",
    "lst3 = [1,3,5,7,9]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.11 µs ± 189 ns per loop (mean ± std. dev. of 7 runs, 100000 loops each)\n"
     ]
    }
   ],
   "source": [
    "%timeit same_diff_ints(lst1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4.24 µs ± 363 ns per loop (mean ± std. dev. of 7 runs, 100000 loops each)\n"
     ]
    }
   ],
   "source": [
    "%timeit same_diff_ints(lst2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'function' object is not subscriptable",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-139-f6aa37115662>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0msame_diff_ints\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mlst3\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m: 'function' object is not subscriptable"
     ]
    }
   ],
   "source": [
    "same_diff_ints[lst3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 0 ns\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 134,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%time lab.same_diff_ints([5,3,1,5,9,8])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Strings and Files\n",
    "\n",
    "The following questions will help you (re)learn the basics of working with strings and reading data from files (which are read in as strings, by default)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "**Question 3 (Prefixes):**\n",
    "\n",
    "Write a function `prefixes` that takes a string and returns a string of every consecutive prefix of the input string. For example, `prefixes('Data!')` should return `'DDaDatDataData!'`.  (See the doctests for more examples).\n",
    "\n",
    "Recall that [strings may be sliced](https://docs.python.org/3/tutorial/introduction.html#strings), like lists.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prefixes(s):\n",
    "    output = ''\n",
    "    for i in range(len(s) + 1):\n",
    "        add = s[0:i]\n",
    "        output += add\n",
    "    return output\n",
    "        \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'aaaaaraaroaaron'"
      ]
     },
     "execution_count": 156,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prefixes('aaron')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "**Question 4 (Evens reversed):**\n",
    "\n",
    "Write a function `evens_reversed` that takes in a non-negative integer $N$ and returns a string containing all even integers from $1$ to $N$ (inclusive) in reversed order, separated by spaces. Additionally, [zero pad](https://www.tutorialspoint.com/python/string_zfill.htm) each integer, so that each has the same length."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 678,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evens_reversed(N):\n",
    "    if N == 0 or N == 1: #nothing returned\n",
    "        return ''\n",
    "\n",
    "    output = ''\n",
    "    num_pads = len(str(N)) #num of digits that will be length of each integer\n",
    "    \n",
    "    for i in range(N, 1, -1):\n",
    "        if (i % 2) == 0:\n",
    "            str_int = str(i)\n",
    "            str_int = str_int.zfill(num_pads) #zeropad the integer\n",
    "            output += str_int\n",
    "            output += ' '\n",
    "        \n",
    "    output = output.strip() #remove whitespace\n",
    "    return output\n",
    "            \n",
    "            \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 679,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'10 08 06 04 02'"
      ]
     },
     "execution_count": 679,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evens_reversed(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' 01 02 03 '"
      ]
     },
     "execution_count": 171,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s = ' 01 02 03 '\n",
    "s.strip()\n",
    "s"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "[Recall](https://docs.python.org/3/tutorial/inputoutput.html#reading-and-writing-files) that the built-in function `open` takes in a file path and returns *a file object* (sometimes called a *file handle*). Below are a few properties of file objects:\n",
    "\n",
    "* `open(path)` opens the file at location `path` for reading.\n",
    "* `open(path)` is an *iterable*, which contains successive lines of the file.\n",
    "* Once a file object is opened, after use it should be closed to avoid memory leaks. To ensure a file is closed once done, you should use a *context manager* as follows:\n",
    "```\n",
    "with open(path) as fh:\n",
    "    for line in fh:\n",
    "        process_line(line)\n",
    "```\n",
    "* To read the entire file into a string, use the read method:\n",
    "```\n",
    "with open(path) as fh:\n",
    "    s = fh.read()\n",
    "```\n",
    "However, you should be careful when reading an entire file into memory that the file isn't too big! *You should avoid this whenever possible!*\n",
    "\n",
    "**Question 5 (Reading Files):**\n",
    "\n",
    "Create a function `last_chars` that takes a file object and returns a string consisting of the last character of the line.\n",
    "\n",
    "*Remark:* A newline is the \"delimiter\" of the lines of a file, and doesn't count as part of the line (as the tests imply). Every other character is part of the line. For more info on this, see [the interpretation](https://en.wikipedia.org/wiki/Newline#Interpretation) of files as a 'newline delimited variables' file.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {},
   "outputs": [],
   "source": [
    "def last_chars(fh):\n",
    "    output = ''\n",
    "    with open(fh.name) as fh:\n",
    "        for line in fh:\n",
    "            output += line[-2]\n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {},
   "outputs": [],
   "source": [
    "fp = os.path.join('data', 'chars.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'hrg'"
      ]
     },
     "execution_count": 205,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f = open(fp)\n",
    "output = ''\n",
    "for line in f:\n",
    "    output += line[-2]\n",
    "    \n",
    "output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## `numpy` exercises\n",
    "\n",
    "For an introduction to arrays and `numpy` recall the relevant section of [DSC 10](https://www.inferentialthinking.com/chapters/05/1/Arrays.html)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question 6 (Basic Arrays):**\n",
    "\n",
    "Create the following functions using `numpy` methods satisfying the requirements given in each part. Your solutions should **not** contain any loops or list comprehensions.\n",
    "\n",
    "* A function `arr_1` that takes in a `numpy` array and adds to each element the square-root of the index of each element.\n",
    "\n",
    "* A function `arr_2` that takes in a `numpy` array of integers and returns a boolean array (i.e. an array of booleans) whose `ith` element is `True` if and only if the `ith` element of the input array is divisble by 16.\n",
    "\n",
    "* A function `arr_3` that takes in a `numpy` array of [stock prices](https://en.wikipedia.org/wiki/Stock) per share on successive days in USD and returns an array of growth rates. That is, the `ith` number of the output array should contain the rate of growth in stock price between the $i^{th}$ day to the $(i+1)^{th}$ day. The growth rate should be a proportion, rounded to the nearest hundredth.\n",
    "\n",
    "* Suppose:\n",
    "    - `A` is a `numpy` array of [stock prices](https://en.wikipedia.org/wiki/Stock) per share for a company on successive days in USD \n",
    "    - you start with \\\\$20, and put aside \\\\$20 at the end of each day to buy as much stock as possible the following day. \n",
    "    - Any money left-over after a given day is saved for possibly buying stock on a future day. \n",
    "    - Create a function `arr_4` that takes in `A` and returns the day on which you can buy at least one share from 'left-over' money. If this never happens, return `-1`. The first stock purchase occurs on day 0. *Note: you cannot buy fractions of a share of stock*.\n",
    "    \n",
    "*Example:* If the stock price is \\\\$3 every day, then the answer is 'day 1':\n",
    "* day 0: buy 6 shares; \\\\$2 left-over; \\\\$22 at end of day.\n",
    "* day 1: buy 7 shares; \\\\$1 left-over; \\\\$21 at end of day.\n",
    "This is more than the 6 shares that \\\\$20 can buy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 422,
   "metadata": {},
   "outputs": [],
   "source": [
    "def arr_4(A):\n",
    "    copy = np.copy(A)\n",
    "    leftovers = 20 % A \n",
    "    total_leftovers = np.cumsum(leftovers) #total leftovers after each day\n",
    "    enough_left = total_leftovers >= A #boolean array to determine whether we have enough to buy another stock for the day\n",
    "    \n",
    "    if True in enough_left:\n",
    "        day = list(enough_left).index(True) #gets first index where we can buy\n",
    "        return day\n",
    "    else:\n",
    "        return -1\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 425,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 425,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numbers\n",
    "stocks = np.array([3, 4, 3])\n",
    "out = arr_4(stocks)\n",
    "out\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 418,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 418,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "A = np.array([3, 3, 3, 3])\n",
    "copy = np.copy(A)\n",
    "\n",
    "leftovers = 20 % A\n",
    "total_leftovers = np.cumsum(leftovers)\n",
    "total_leftovers\n",
    "\n",
    "\n",
    "enough_left = total_leftovers >= A\n",
    "list(enough_left).index(True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Getting Started with Pandas\n",
    "\n",
    "The following questions will help you get comfortable with Pandas. These questions are similar to questions on tables in DSC 10; review the [textbook](https://www.inferentialthinking.com) as necessary. As always for Pandas questions:\n",
    "1. Avoid writing loops through the rows of the dataset to do the problem, and\n",
    "2. Test the output/correctness of your code with the help of the dataset given, but be sure your code will also run on data \"like\" the dataset given (sampling rows using the `.sample` method is useful for this!).\n",
    "\n",
    "**Question 7 (Pandas basics):**\n",
    "\n",
    "Read in the file `movies_by_year.csv` in the `data` directory and understand the dataset by answering the following questions. To do this, create a function `movie_stats` that takes in a dataframe like `movies` and returns a series containing the following statistics:\n",
    "* The number of years covered by the dataset (`num_years`).\n",
    "* The total number of movies made over all years in the dataset (`tot_movies`).\n",
    "* The year with the fewest number of movies made; a tie should return the earliest year (`yr_fewest_movies`).\n",
    "* The average amount of money grossed over all the years in the dataset (`avg_gross`).\n",
    "* The year with the highest gross *per movie* (`highest_per_movie`).\n",
    "* The name of the top movie during the second-lowest (total) grossing year (`second_lowest`).\n",
    "* The average number of movies made the year *after* a Harry Potter movie was the #1 movie (`avg_after_harry`).\n",
    "\n",
    "The index of the output series are given in parenthesis above.\n",
    "\n",
    "*Note*: Your function should work on a dataset of the same format that contains information from other years. You may assume that none of the answers involving ranking returns a tie.\n",
    "\n",
    "*Note*: To make sure your function still runs, in the event that one of the 7 parts throws an exception (e.g. due to a very incorrect answer), use `Try... Except...` structures."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 665,
   "metadata": {},
   "outputs": [],
   "source": [
    "movie_fp = os.path.join('data', 'movies_by_year.csv')\n",
    "movies = pd.read_csv(movie_fp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 672,
   "metadata": {},
   "outputs": [],
   "source": [
    "def movie_stats(movies):\n",
    "             \n",
    "    def num_years():\n",
    "        \"\"\"number of years covered in the dataset\"\"\"\n",
    "        years = movies['Year']\n",
    "        return ('num_years', years.nunique())\n",
    "\n",
    "    def tot_movies():\n",
    "        \"\"\"total number of movies over all years\"\"\"\n",
    "        total = movies['Number of Movies'].sum()\n",
    "        return ('tot_movies', total)\n",
    "\n",
    "    def yr_fewest_movies():\n",
    "        \"\"\"year with fewest movies made (earliest)\"\"\"\n",
    "        copy = movies.copy()\n",
    "        year = copy.sort_values(['Number of Movies', 'Year']).reset_index(drop = True).Year.loc[0]\n",
    "        return ('yr_fewest_movies', year)\n",
    "\n",
    "    def avg_gross():\n",
    "        \"\"\"average amount of money grossed over all years\"\"\"\n",
    "        avg = movies['Total Gross'].mean()\n",
    "        if avg is np.nan:\n",
    "            raise\n",
    "        return ('avg_gross', avg)\n",
    "\n",
    "    def highest_per_movie():\n",
    "        \"\"\"The year with the highest gross per movie\"\"\"\n",
    "        copy = movies.copy()\n",
    "        copy['Gross Per Movie'] = copy['Total Gross'] / copy['Number of Movies'] #calculate gross per movie\n",
    "        year = copy.sort_values(['Gross Per Movie'], ascending = False).reset_index(drop = True).Year.loc[0]\n",
    "        return ('highest_per_movie', year)\n",
    "\n",
    "    def second_lowest():\n",
    "        \"\"\"name of the top movie during the second lowest (total) grossing year\"\"\"\n",
    "        copy = movies.copy()\n",
    "        name = copy.sort_values(['Total Gross']).reset_index(drop = True)['#1 Movie'].loc[1]\n",
    "        return ('second_lowest', name)\n",
    "\n",
    "    def avg_after_harry():\n",
    "        \"\"\"avg number of movies made the year after an HP movie was #1 movie\"\"\"\n",
    "        copy = movies.copy()\n",
    "        copy = copy.sort_values(['Year']).reset_index(drop = True) #years early to present\n",
    "        harry_years = copy[copy['#1 Movie'].str.contains('Harry')].Year #years where harry potter was #1\n",
    "        next_years = harry_years + 1 \n",
    "        check = list(next_years.values)\n",
    "        next_years_df = copy[copy['Year'].isin(check)]\n",
    "        avg = next_years_df['Number of Movies'].mean()\n",
    "        if avg is np.nan:\n",
    "            raise\n",
    "        return ('avg_after_harry', avg)\n",
    "    \n",
    "    functions = [num_years(), tot_movies(), yr_fewest_movies(), avg_gross(), highest_per_movie(), second_lowest(), avg_after_harry()]\n",
    "    stats = {}\n",
    "    for fxn in functions:\n",
    "        try:\n",
    "            info = fxn\n",
    "            stats[info[0]] = info[1]\n",
    "        except:\n",
    "            continue\n",
    "    series = pd.Series(stats)\n",
    "            \n",
    "    return series"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 673,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "num_years                            34\n",
       "tot_movies                        17834\n",
       "yr_fewest_movies                   1990\n",
       "avg_gross                       7226.91\n",
       "highest_per_movie                  2009\n",
       "second_lowest        Back to the Future\n",
       "avg_after_harry                     573\n",
       "dtype: object"
      ]
     },
     "execution_count": 673,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out = movie_stats(movies)\n",
    "out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 662,
   "metadata": {},
   "outputs": [],
   "source": [
    "    >>> movie_fp = os.path.join('data', 'movies_by_year.csv')\n",
    "    >>> movies = pd.read_csv(movie_fp)\n",
    "    >>> out = movie_stats(movies)\n",
    "    >>> isinstance(out, pd.Series)\n",
    "    True\n",
    "    >>> 'num_years' in out.index\n",
    "    True\n",
    "    >>> isinstance(out.loc['second_lowest'], str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 387,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Year</th>\n",
       "      <th>Total Gross</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>2010</td>\n",
       "      <td>50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>2011</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>2012</td>\n",
       "      <td>30</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Year  Total Gross\n",
       "0  2010           50\n",
       "1  2011           20\n",
       "2  2012           30"
      ]
     },
     "execution_count": 387,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "column_dict = {'Year': [2010, 2011, 2012, 2010],\n",
    "                'Total Gross': [10, 20, 30, 40]\n",
    "              }\n",
    "test = pd.DataFrame(column_dict)\n",
    "test.groupby('Year', as_index = False).sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## CSV Files\n",
    "\n",
    "**Question 8 (Reading malformed csv files):**\n",
    "\n",
    "`malformed.csv` contains a file of comma-separated values, containing the following fields:\n",
    "\n",
    "\n",
    "|column name|description|type|\n",
    "|---|---|---|\n",
    "|first|first name of person|str|\n",
    "|last|last name of person|str|\n",
    "|weight|weight of person (lbs)|float|\n",
    "|height|height of person (in)|float|\n",
    "|geo|location of person; comma-separated latitude/longitude|str|\n",
    "\n",
    "Unfortunately, the entries contains errors that cause the Pandas `read_csv` function to fail parsing the file with the default settings. Instead, you must read in the file manually using Python's built-in `open` function.\n",
    "\n",
    "Clean the csv file into a Pandas DataFrame with columns as described in the table above, by creating a function called `parse_malformed` that takes in a file path and returns a parsed, properly-typed dataframe. The dataframe should contain columns as described in the table above (with the specified types); it should agree with `pd.read_csv` when the lines are not malformed.\n",
    "\n",
    "\n",
    "*Note:* Assume that the given csv file is a sample of a larger file; you will be graded against a **different** sample of the larger file that has the same type of parsing errors. That is, you should **not** hard-code your cleaning of the data to specific errors on specific lines in the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 530,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 530,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fp = os.path.join('data', 'malformed.csv')\n",
    "df = parse_malformed(fp)\n",
    "dg = pd.read_csv(fp, nrows=4, skiprows=10, names=cols)\n",
    "dg.index = range(9, 13)\n",
    "(dg == df.iloc[9:13]).all().all()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 535,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_malformed(fp):\n",
    "    row_data=[]\n",
    "    cols = ['first', 'last', 'weight', 'height', 'geo']\n",
    "\n",
    "    with open(fp) as fh:\n",
    "\n",
    "        fh.readline() #skip first line (column names)\n",
    "\n",
    "        for line in fh:\n",
    "            #remove newline character\n",
    "            line = line.strip('\\n')\n",
    "            elems = line.split(\",\") #all entries converted to string - last col value not split\n",
    "            elems = list(filter(None, elems)) #remove empty entries\n",
    "\n",
    "            #there should be 6 entries in the list now\n",
    "            for i in range(6): \n",
    "                elems[i] = elems[i].replace('\"', '') #drop quotations in all values\n",
    "                if i == 2 or i == 3: #float columns\n",
    "                    elems[i] = float(elems[i])\n",
    "\n",
    "            #combine index 4 and 5 to make geo column\n",
    "            elems[4] = elems[4] + ',' + elems[5]\n",
    "            del elems[-1]  \n",
    "            #add to row data\n",
    "            row_data.append(elems)\n",
    "\n",
    "    #make new dataframe\n",
    "    output = pd.DataFrame(row_data, columns = cols)\n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 565,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>first</th>\n",
       "      <th>last</th>\n",
       "      <th>weight</th>\n",
       "      <th>height</th>\n",
       "      <th>geo</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>51</td>\n",
       "      <td>Tori</td>\n",
       "      <td>Adithi</td>\n",
       "      <td>187.0</td>\n",
       "      <td>68.0</td>\n",
       "      <td>35.5,-12.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>52</td>\n",
       "      <td>Carolina</td>\n",
       "      <td>Cecille</td>\n",
       "      <td>154.0</td>\n",
       "      <td>71.0</td>\n",
       "      <td>38.6,12.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>53</td>\n",
       "      <td>Emmanuel</td>\n",
       "      <td>Leidi</td>\n",
       "      <td>112.0</td>\n",
       "      <td>61.0</td>\n",
       "      <td>37.6,64.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>54</td>\n",
       "      <td>Andrew</td>\n",
       "      <td>Vikrant</td>\n",
       "      <td>90.0</td>\n",
       "      <td>61.0</td>\n",
       "      <td>36.6,36.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>55</td>\n",
       "      <td>Donovan</td>\n",
       "      <td>Randa</td>\n",
       "      <td>120.0</td>\n",
       "      <td>73.0</td>\n",
       "      <td>36.5,28.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>56</td>\n",
       "      <td>Rachel</td>\n",
       "      <td>Alexiz</td>\n",
       "      <td>145.0</td>\n",
       "      <td>67.0</td>\n",
       "      <td>38.0,36.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>57</td>\n",
       "      <td>Dylan</td>\n",
       "      <td>Aryon</td>\n",
       "      <td>104.0</td>\n",
       "      <td>65.0</td>\n",
       "      <td>35.0,18.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>58</td>\n",
       "      <td>Jeevan</td>\n",
       "      <td>Ardit</td>\n",
       "      <td>148.0</td>\n",
       "      <td>71.0</td>\n",
       "      <td>36.9,-58.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>59</td>\n",
       "      <td>Kaitlin</td>\n",
       "      <td>Isrrael</td>\n",
       "      <td>108.0</td>\n",
       "      <td>78.0</td>\n",
       "      <td>36.2,16.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>60</td>\n",
       "      <td>Vanessa</td>\n",
       "      <td>Guiselle</td>\n",
       "      <td>96.0</td>\n",
       "      <td>77.0</td>\n",
       "      <td>38.0,86.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>61</td>\n",
       "      <td>Alyssa</td>\n",
       "      <td>Gillian</td>\n",
       "      <td>88.0</td>\n",
       "      <td>69.0</td>\n",
       "      <td>38.2,252.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>62</td>\n",
       "      <td>Christina</td>\n",
       "      <td>Jerard</td>\n",
       "      <td>178.0</td>\n",
       "      <td>77.0</td>\n",
       "      <td>38.2,-57.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>63</td>\n",
       "      <td>Hayli</td>\n",
       "      <td>Marton</td>\n",
       "      <td>125.0</td>\n",
       "      <td>73.0</td>\n",
       "      <td>37.7,-93.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>64</td>\n",
       "      <td>Isabella</td>\n",
       "      <td>Laverne</td>\n",
       "      <td>117.0</td>\n",
       "      <td>76.0</td>\n",
       "      <td>36.4,88.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>65</td>\n",
       "      <td>Parker</td>\n",
       "      <td>Kerly</td>\n",
       "      <td>160.0</td>\n",
       "      <td>59.0</td>\n",
       "      <td>36.7,139.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>66</td>\n",
       "      <td>Madeleine</td>\n",
       "      <td>Amritpal</td>\n",
       "      <td>166.0</td>\n",
       "      <td>58.0</td>\n",
       "      <td>36.2,51.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>67</td>\n",
       "      <td>Keaton</td>\n",
       "      <td>Kinzy</td>\n",
       "      <td>119.0</td>\n",
       "      <td>64.0</td>\n",
       "      <td>36.4,20.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>68</td>\n",
       "      <td>Mercedes</td>\n",
       "      <td>Tarika</td>\n",
       "      <td>129.0</td>\n",
       "      <td>70.0</td>\n",
       "      <td>37.0,-56.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>69</td>\n",
       "      <td>Dallen</td>\n",
       "      <td>Keshae</td>\n",
       "      <td>127.0</td>\n",
       "      <td>75.0</td>\n",
       "      <td>37.1,-113.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>70</td>\n",
       "      <td>Shay</td>\n",
       "      <td>Marcea</td>\n",
       "      <td>103.0</td>\n",
       "      <td>65.0</td>\n",
       "      <td>36.0,-33.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>71</td>\n",
       "      <td>Adrianna</td>\n",
       "      <td>Karsten</td>\n",
       "      <td>157.0</td>\n",
       "      <td>81.0</td>\n",
       "      <td>34.8,36.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>72</td>\n",
       "      <td>Max</td>\n",
       "      <td>Nairi</td>\n",
       "      <td>113.0</td>\n",
       "      <td>67.0</td>\n",
       "      <td>36.9,12.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>73</td>\n",
       "      <td>Suzanne</td>\n",
       "      <td>Dearion</td>\n",
       "      <td>129.0</td>\n",
       "      <td>70.0</td>\n",
       "      <td>36.9,-70.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>74</td>\n",
       "      <td>Camryn</td>\n",
       "      <td>Tasnim</td>\n",
       "      <td>126.0</td>\n",
       "      <td>63.0</td>\n",
       "      <td>36.5,19.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>75</td>\n",
       "      <td>Cielo</td>\n",
       "      <td>Saylah</td>\n",
       "      <td>103.0</td>\n",
       "      <td>65.0</td>\n",
       "      <td>36.1,83.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>76</td>\n",
       "      <td>Annastasia</td>\n",
       "      <td>Averi</td>\n",
       "      <td>91.0</td>\n",
       "      <td>67.0</td>\n",
       "      <td>37.1,-43.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>77</td>\n",
       "      <td>Hannah</td>\n",
       "      <td>Jerit</td>\n",
       "      <td>142.0</td>\n",
       "      <td>53.0</td>\n",
       "      <td>36.6,10.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>78</td>\n",
       "      <td>Jovita</td>\n",
       "      <td>Marquaveon</td>\n",
       "      <td>150.0</td>\n",
       "      <td>70.0</td>\n",
       "      <td>38.2,-32.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>79</td>\n",
       "      <td>Jasmine</td>\n",
       "      <td>Jahmal</td>\n",
       "      <td>107.0</td>\n",
       "      <td>72.0</td>\n",
       "      <td>38.5,9.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>80</td>\n",
       "      <td>Cheyenne</td>\n",
       "      <td>Gerrid</td>\n",
       "      <td>55.0</td>\n",
       "      <td>71.0</td>\n",
       "      <td>36.6,68.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>81</td>\n",
       "      <td>Karma</td>\n",
       "      <td>Nameer</td>\n",
       "      <td>131.0</td>\n",
       "      <td>65.0</td>\n",
       "      <td>37.5,69.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>82</td>\n",
       "      <td>Madeline</td>\n",
       "      <td>Cira</td>\n",
       "      <td>128.0</td>\n",
       "      <td>65.0</td>\n",
       "      <td>37.4,149.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>83</td>\n",
       "      <td>Connor</td>\n",
       "      <td>Sheridyn</td>\n",
       "      <td>141.0</td>\n",
       "      <td>73.0</td>\n",
       "      <td>36.8,-80.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>84</td>\n",
       "      <td>Sarah</td>\n",
       "      <td>Sunday</td>\n",
       "      <td>180.0</td>\n",
       "      <td>54.0</td>\n",
       "      <td>36.7,-5.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>85</td>\n",
       "      <td>Victoria</td>\n",
       "      <td>Maliik</td>\n",
       "      <td>164.0</td>\n",
       "      <td>60.0</td>\n",
       "      <td>36.3,151.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>86</td>\n",
       "      <td>George</td>\n",
       "      <td>Tyshonna</td>\n",
       "      <td>105.0</td>\n",
       "      <td>74.0</td>\n",
       "      <td>37.5,-91.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>87</td>\n",
       "      <td>Marquis</td>\n",
       "      <td>Kylar</td>\n",
       "      <td>137.0</td>\n",
       "      <td>51.0</td>\n",
       "      <td>38.2,228.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>88</td>\n",
       "      <td>Marlene</td>\n",
       "      <td>Fatuma</td>\n",
       "      <td>117.0</td>\n",
       "      <td>64.0</td>\n",
       "      <td>36.4,-9.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>89</td>\n",
       "      <td>Kathryn</td>\n",
       "      <td>Diondra</td>\n",
       "      <td>149.0</td>\n",
       "      <td>65.0</td>\n",
       "      <td>38.3,68.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>90</td>\n",
       "      <td>Jonathan</td>\n",
       "      <td>Jersey</td>\n",
       "      <td>107.0</td>\n",
       "      <td>77.0</td>\n",
       "      <td>36.0,11.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>91</td>\n",
       "      <td>Joshua</td>\n",
       "      <td>Caileen</td>\n",
       "      <td>181.0</td>\n",
       "      <td>67.0</td>\n",
       "      <td>37.3,79.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>92</td>\n",
       "      <td>Emily</td>\n",
       "      <td>Leonid</td>\n",
       "      <td>146.0</td>\n",
       "      <td>57.0</td>\n",
       "      <td>37.8,-68.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>93</td>\n",
       "      <td>Jacqualyn</td>\n",
       "      <td>Angelea</td>\n",
       "      <td>116.0</td>\n",
       "      <td>63.0</td>\n",
       "      <td>36.4,-31.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>94</td>\n",
       "      <td>Gionna</td>\n",
       "      <td>Pamala</td>\n",
       "      <td>180.0</td>\n",
       "      <td>79.0</td>\n",
       "      <td>38.6,-28.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>95</td>\n",
       "      <td>Yasmeen</td>\n",
       "      <td>Jahron</td>\n",
       "      <td>135.0</td>\n",
       "      <td>84.0</td>\n",
       "      <td>38.3,-127.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>96</td>\n",
       "      <td>Meghan</td>\n",
       "      <td>Carlyann</td>\n",
       "      <td>101.0</td>\n",
       "      <td>66.0</td>\n",
       "      <td>36.6,80.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>97</td>\n",
       "      <td>Tess</td>\n",
       "      <td>Shree</td>\n",
       "      <td>146.0</td>\n",
       "      <td>68.0</td>\n",
       "      <td>38.8,64.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>98</td>\n",
       "      <td>Maria</td>\n",
       "      <td>Kalvyn</td>\n",
       "      <td>115.0</td>\n",
       "      <td>51.0</td>\n",
       "      <td>37.1,-90.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>99</td>\n",
       "      <td>Lexie</td>\n",
       "      <td>Cheyenna</td>\n",
       "      <td>151.0</td>\n",
       "      <td>71.0</td>\n",
       "      <td>35.9,86.1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         first        last  weight  height          geo\n",
       "51        Tori      Adithi   187.0    68.0   35.5,-12.4\n",
       "52    Carolina     Cecille   154.0    71.0    38.6,12.4\n",
       "53    Emmanuel       Leidi   112.0    61.0    37.6,64.6\n",
       "54      Andrew     Vikrant    90.0    61.0    36.6,36.9\n",
       "55     Donovan       Randa   120.0    73.0    36.5,28.2\n",
       "56      Rachel      Alexiz   145.0    67.0    38.0,36.4\n",
       "57       Dylan       Aryon   104.0    65.0    35.0,18.0\n",
       "58      Jeevan       Ardit   148.0    71.0   36.9,-58.9\n",
       "59     Kaitlin     Isrrael   108.0    78.0    36.2,16.0\n",
       "60     Vanessa    Guiselle    96.0    77.0    38.0,86.0\n",
       "61      Alyssa     Gillian    88.0    69.0   38.2,252.0\n",
       "62   Christina      Jerard   178.0    77.0   38.2,-57.5\n",
       "63       Hayli      Marton   125.0    73.0   37.7,-93.7\n",
       "64    Isabella     Laverne   117.0    76.0    36.4,88.1\n",
       "65      Parker       Kerly   160.0    59.0   36.7,139.3\n",
       "66   Madeleine    Amritpal   166.0    58.0    36.2,51.4\n",
       "67      Keaton       Kinzy   119.0    64.0    36.4,20.5\n",
       "68    Mercedes      Tarika   129.0    70.0   37.0,-56.8\n",
       "69      Dallen      Keshae   127.0    75.0  37.1,-113.1\n",
       "70        Shay      Marcea   103.0    65.0   36.0,-33.1\n",
       "71    Adrianna     Karsten   157.0    81.0    34.8,36.1\n",
       "72         Max       Nairi   113.0    67.0    36.9,12.2\n",
       "73     Suzanne     Dearion   129.0    70.0   36.9,-70.4\n",
       "74      Camryn      Tasnim   126.0    63.0    36.5,19.8\n",
       "75       Cielo      Saylah   103.0    65.0    36.1,83.1\n",
       "76  Annastasia       Averi    91.0    67.0   37.1,-43.7\n",
       "77      Hannah       Jerit   142.0    53.0    36.6,10.3\n",
       "78      Jovita  Marquaveon   150.0    70.0   38.2,-32.6\n",
       "79     Jasmine      Jahmal   107.0    72.0     38.5,9.1\n",
       "80    Cheyenne      Gerrid    55.0    71.0    36.6,68.2\n",
       "81       Karma      Nameer   131.0    65.0    37.5,69.8\n",
       "82    Madeline        Cira   128.0    65.0   37.4,149.6\n",
       "83      Connor    Sheridyn   141.0    73.0   36.8,-80.7\n",
       "84       Sarah      Sunday   180.0    54.0    36.7,-5.6\n",
       "85    Victoria      Maliik   164.0    60.0   36.3,151.2\n",
       "86      George    Tyshonna   105.0    74.0   37.5,-91.5\n",
       "87     Marquis       Kylar   137.0    51.0   38.2,228.4\n",
       "88     Marlene      Fatuma   117.0    64.0    36.4,-9.5\n",
       "89     Kathryn     Diondra   149.0    65.0    38.3,68.0\n",
       "90    Jonathan      Jersey   107.0    77.0    36.0,11.8\n",
       "91      Joshua     Caileen   181.0    67.0    37.3,79.0\n",
       "92       Emily      Leonid   146.0    57.0   37.8,-68.7\n",
       "93   Jacqualyn     Angelea   116.0    63.0   36.4,-31.5\n",
       "94      Gionna      Pamala   180.0    79.0   38.6,-28.6\n",
       "95     Yasmeen      Jahron   135.0    84.0  38.3,-127.3\n",
       "96      Meghan    Carlyann   101.0    66.0    36.6,80.5\n",
       "97        Tess       Shree   146.0    68.0    38.8,64.9\n",
       "98       Maria      Kalvyn   115.0    51.0   37.1,-90.4\n",
       "99       Lexie    Cheyenna   151.0    71.0    35.9,86.1"
      ]
     },
     "execution_count": 565,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fp = os.path.join('data', 'malformed.csv')\n",
    "df = parse_malformed(fp)\n",
    "df.loc[51:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Congratulations! You're done!\n",
    "\n",
    "* Submit the lab on Gradescope"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 453,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>e</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [e, 2, 3]\n",
       "Index: []"
      ]
     },
     "execution_count": 453,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dictionary = {'e': [], '2': [], '3': []}\n",
    "n = pd.DataFrame(dictionary)\n",
    "n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernel_info": {
   "name": "python3"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  },
  "nteract": {
   "version": "0.15.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

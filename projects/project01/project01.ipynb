{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# ---------------------------------------------------------------------\n",
    "# Question #1\n",
    "# ---------------------------------------------------------------------\n",
    "\n",
    "\n",
    "def get_assignment_names(grades):\n",
    "    '''\n",
    "    get_assignment_names takes in a dataframe like grades and returns\n",
    "    a dictionary with the following structure:\n",
    "\n",
    "    The keys are the general areas of the syllabus: lab, project,\n",
    "    midterm, final, disc, checkpoint\n",
    "\n",
    "    The values are lists that contain the assignment names of that type.\n",
    "    For example the lab assignments all have names of the form labXX where XX\n",
    "    is a zero-padded two digit number. See the doctests for more details.\n",
    "\n",
    "    :Example:\n",
    "    >>> grades_fp = os.path.join('data', 'grades.csv')\n",
    "    >>> grades = pd.read_csv(grades_fp)\n",
    "    >>> names = get_assignment_names(grades)\n",
    "    >>> set(names.keys()) == {'lab', 'project', 'midterm', 'final', 'disc', 'checkpoint'}\n",
    "    True\n",
    "    >>> names['final'] == ['Final']\n",
    "    True\n",
    "    >>> 'project02' in names['project']\n",
    "    True\n",
    "    '''\n",
    "\n",
    "    names = {'lab':[], 'project': [], 'midterm':['Midterm'], 'final':['Final'], 'disc':[], 'checkpoint':[]}\n",
    "\n",
    "    for col in grades.columns:\n",
    "        if ('lab' in col) and (len(col) == 5):\n",
    "            names['lab'].append(col)\n",
    "        elif ('project' in col) and (len(col) == 9):\n",
    "            names['project'].append(col)\n",
    "        elif ('discussion' in col) and (len(col) == 12):\n",
    "            names['disc'].append(col)\n",
    "        elif ('checkpoint' in col) and (len(col) == 22):\n",
    "            names['checkpoint'].append(col)\n",
    "\n",
    "    return names\n",
    "\n",
    "\n",
    "# ---------------------------------------------------------------------\n",
    "# Question #2\n",
    "# ---------------------------------------------------------------------\n",
    "\n",
    "\n",
    "def projects_total(grades):\n",
    "    '''\n",
    "    projects_total that takes in grades and computes the total project grade\n",
    "    for the quarter according to the syllabus.\n",
    "    The output Series should contain values between 0 and 1.\n",
    "\n",
    "    :Example:\n",
    "    >>> grades_fp = os.path.join('data', 'grades.csv')\n",
    "    >>> grades = pd.read_csv(grades_fp)\n",
    "    >>> out = projects_total(grades)\n",
    "    >>> np.all((0 <= out) & (out <= 1))\n",
    "    True\n",
    "    >>> 0.7 < out.mean() < 0.9\n",
    "    True\n",
    "    '''\n",
    "    names = get_assignment_names(grades)\n",
    "\n",
    "    copy = grades.copy()\n",
    "    project_scores = []\n",
    "\n",
    "    #loop thru projects\n",
    "    for project_name in names['project']:\n",
    "        #check if theres a free response\n",
    "        if project_name + '_free_response' in copy.columns:\n",
    "            project_fr_name = project_name + '_free_response'\n",
    "        else:\n",
    "            project_fr_name = None\n",
    "        #handle NaN values to get 0 score\n",
    "        copy[project_name] = copy[project_name].fillna(0)\n",
    "        if project_fr_name != None: #free response exists\n",
    "            copy[project_fr_name] = copy[project_fr_name].fillna(0)\n",
    "\n",
    "        #numerator\n",
    "        if project_fr_name != None: #free response exists\n",
    "            points = copy[project_name] + copy[project_fr_name]\n",
    "        else:\n",
    "            points = copy[project_name]\n",
    "        #denominator\n",
    "        if project_fr_name != None: #free response exists\n",
    "            total_points = copy[project_name + ' - Max Points'] + copy[project_fr_name + ' - Max Points']\n",
    "        else:\n",
    "            total_points = copy[project_name + ' - Max Points']\n",
    "\n",
    "        #compute scores for this project\n",
    "        score = points/total_points\n",
    "        project_scores.append(score)\n",
    "\n",
    "    total_scores = sum(project_scores) / len(names['project']) #divided by number of projects\n",
    "    return total_scores\n",
    "\n",
    "# ---------------------------------------------------------------------\n",
    "# Question # 3\n",
    "# ---------------------------------------------------------------------\n",
    "\n",
    "\n",
    "def last_minute_submissions(grades):\n",
    "    \"\"\"\n",
    "    last_minute_submissions takes in the dataframe\n",
    "    grades and a Series indexed by lab assignment that\n",
    "    contains the number of submissions that were turned\n",
    "    in on time by the student, yet marked 'late' by Gradescope.\n",
    "\n",
    "    :Example:\n",
    "    >>> fp = os.path.join('data', 'grades.csv')\n",
    "    >>> grades = pd.read_csv(fp)\n",
    "    >>> out = last_minute_submissions(grades)\n",
    "    >>> isinstance(out, pd.Series)\n",
    "    True\n",
    "    >>> np.all(out.index == ['lab0%d' % d for d in range(1,10)])\n",
    "    True\n",
    "    >>> (out > 0).sum()\n",
    "    8\n",
    "    \"\"\"\n",
    "\n",
    "    late_tag = ' - Lateness (H:M:S)'\n",
    "\n",
    "    names = get_assignment_names(grades)\n",
    "\n",
    "    late_submissions = {}\n",
    "\n",
    "    for lab in names['lab']:\n",
    "\n",
    "        gradescope_late = grades.copy()\n",
    "\n",
    "        gradescope_late = gradescope_late[gradescope_late[lab + late_tag] != '00:00:00']\n",
    "\n",
    "        gradescope_late[lab + late_tag] = gradescope_late[lab + late_tag].str.slice(stop = 2)\n",
    "\n",
    "        gradescope_late[lab + late_tag] = gradescope_late[lab + late_tag].astype(int)\n",
    "\n",
    "        error_late = gradescope_late.loc[gradescope_late[lab + late_tag] < 9]\n",
    "\n",
    "        late_submissions[lab] = len(error_late)\n",
    "\n",
    "    series = pd.Series(late_submissions)\n",
    "    return series\n",
    "\n",
    "\n",
    "# ---------------------------------------------------------------------\n",
    "# Question #4\n",
    "# ---------------------------------------------------------------------\n",
    "\n",
    "def lateness_penalty(col):\n",
    "    \"\"\"\n",
    "    lateness_penalty takes in a 'lateness' column and returns\n",
    "    a column of penalties according to the syllabus.\n",
    "\n",
    "    :Example:\n",
    "    >>> fp = os.path.join('data', 'grades.csv')\n",
    "    >>> col = pd.read_csv(fp)['lab01 - Lateness (H:M:S)']\n",
    "    >>> out = lateness_penalty(col)\n",
    "    >>> isinstance(out, pd.Series)\n",
    "    True\n",
    "    >>> set(out.unique()) <= {1.0, 0.9, 0.8, 0.5}\n",
    "    True\n",
    "    \"\"\"\n",
    "\n",
    "    #make series, starting with all 1.0 penalties\n",
    "    penalties = pd.Series(1.0, index = col.index)\n",
    "\n",
    "    #convert times to numbers\n",
    "    col1 = col.str.contains('00:00:00')\n",
    "    ontime_gc = col1[col1].index    \n",
    "    col = col.drop(index = ontime_gc)\n",
    "    \n",
    "    if (col.empty == False): # there are lates to account for\n",
    "        hours = col.str.split(':', 1, True)\n",
    "        hours[0] = hours[0].astype(int)\n",
    "        hours[1] = hours[1].str.contains('00:00')\n",
    "        hours[0] = hours[0] + ~hours[1]\n",
    "        hours = hours[0]\n",
    "\n",
    "        #late 1 week (before 9 AM doesn't count)\n",
    "        week_late = hours[hours.between(9, 168)]\n",
    "        week_late_indices = week_late.index.values\n",
    "        penalties[week_late_indices] = 0.9\n",
    "\n",
    "        #late 2 weeks\n",
    "        two_weeks = hours[hours.between(169, 336)]\n",
    "        two_weeks_indices = two_weeks.index.values\n",
    "        penalties[two_weeks_indices] = 0.8\n",
    "\n",
    "        #beyond\n",
    "        beyond = hours[hours >= 337]\n",
    "        beyond_indices = beyond.index.values\n",
    "        penalties[beyond_indices] = 0.5\n",
    "    \n",
    "    return penalties\n",
    "\n",
    "\n",
    "# ---------------------------------------------------------------------\n",
    "# Question #5\n",
    "# ---------------------------------------------------------------------\n",
    "\n",
    "def process_labs(grades):\n",
    "    \"\"\"\n",
    "    process_labs that takes in a dataframe like grades and returns\n",
    "    a dataframe of processed lab scores. The output should:\n",
    "      * share the same index as grades,\n",
    "      * have columns given by the lab assignment names (e.g. lab01,...lab10)\n",
    "      * have values representing the lab grades for each assignment,\n",
    "        adjusted for Lateness and scaled to a score between 0 and 1.\n",
    "\n",
    "    :Example:\n",
    "    >>> fp = os.path.join('data', 'grades.csv')\n",
    "    >>> grades = pd.read_csv(fp)\n",
    "    >>> out = process_labs(grades)\n",
    "    >>> out.columns.tolist() == ['lab%02d' % x for x in range(1,10)]\n",
    "    True\n",
    "    >>> np.all((0.65 <= out.mean()) & (out.mean() <= 0.90))\n",
    "    True\n",
    "    \"\"\"\n",
    "\n",
    "    #do we need to handle NaNs?\n",
    "    grades = grades.replace({np.nan: 0})\n",
    "    \n",
    "    new_df = pd.DataFrame()\n",
    "    lab_titles = get_assignment_names(grades)['lab']\n",
    "    lateness =  ' - Lateness (H:M:S)'\n",
    "    max_p = ' - Max Points'\n",
    "    \n",
    "    for col in lab_titles:\n",
    "        new_df[col] = (grades[col] / grades[col + max_p]) * lateness_penalty(grades[col + lateness])\n",
    "        \n",
    "    return new_df\n",
    "\n",
    "\n",
    "# ---------------------------------------------------------------------\n",
    "# Question #6\n",
    "# ---------------------------------------------------------------------\n",
    "\n",
    "def lab_total(processed):\n",
    "    \"\"\"\n",
    "    lab_total takes in dataframe of processed assignments (like the output of\n",
    "    Question 5) and computes the total lab grade for each student according to\n",
    "    the syllabus (returning a Series).\n",
    "\n",
    "    Your answers should be proportions between 0 and 1.\n",
    "\n",
    "    :Example:\n",
    "    >>> cols = 'lab01 lab02 lab03'.split()\n",
    "    >>> processed = pd.DataFrame([[0.2, 0.90, 1.0]], index=[0], columns=cols)\n",
    "    >>> np.isclose(lab_total(processed), 0.95).all()\n",
    "    True\n",
    "    \"\"\"\n",
    "\n",
    "    # clean out the nans (turn to 0)\n",
    "    processed = processed.replace({np.nan: 0})\n",
    "    n = len(processed.columns) - 1\n",
    "    \n",
    "    lowest = processed.min(axis = 1)\n",
    "    summed = processed.sum(axis = 1)\n",
    "    total = summed - lowest\n",
    "    \n",
    "    return total / n\n",
    "\n",
    "# ---------------------------------------------------------------------\n",
    "# Question # 7\n",
    "# ---------------------------------------------------------------------\n",
    "\n",
    "# checkpoints \n",
    "def checkpoint_total(grades):\n",
    "    grades = grades.replace({np.nan: 0})\n",
    "    columns = get_assignment_names(grades)\n",
    "    col_name = ' - Max Points'\n",
    "    checkpoint_scores = []\n",
    "    \n",
    "    for col in columns['checkpoint']:\n",
    "        checkpoint_scores.append(grades[col] / grades[col + col_name])\n",
    "        \n",
    "    total_checkpoint = sum(checkpoint_scores) / len(columns['checkpoint'])\n",
    "    \n",
    "    return total_checkpoint\n",
    "\n",
    "\n",
    "# discussion\n",
    "def discussion_total(grades):\n",
    "    grades = grades.replace({np.nan: 0})\n",
    "    columns = get_assignment_names(grades)\n",
    "    col_name = ' - Max Points'\n",
    "    discussion_scores = []\n",
    "    \n",
    "    for col in columns['disc']:\n",
    "        discussion_scores.append(grades[col] / grades[col + col_name])\n",
    "        \n",
    "    total_discussion = sum(discussion_scores) / len(columns['disc'])\n",
    "    \n",
    "    return total_discussion\n",
    "\n",
    "\n",
    "def total_points(grades):\n",
    "    \"\"\"\n",
    "    total_points takes in grades and returns the final\n",
    "    course grades according to the syllabus. Course grades\n",
    "    should be proportions between zero and one.\n",
    "\n",
    "    :Example:\n",
    "    >>> fp = os.path.join('data', 'grades.csv')\n",
    "    >>> grades = pd.read_csv(fp)\n",
    "    >>> out = total_points(grades)\n",
    "    >>> np.all((0 <= out) & (out <= 1))\n",
    "    True\n",
    "    >>> 0.7 < out.mean() < 0.9\n",
    "    True\n",
    "    \"\"\"\n",
    "\n",
    "    grades = grades.replace({np.nan: 0})\n",
    "    \n",
    "    # lab total\n",
    "    processed = process_labs(grades)\n",
    "    lab_scores = lab_total(processed)\n",
    "    \n",
    "    # project total\n",
    "    project_scores = projects_total(grades)\n",
    "    \n",
    "    # checkpoint total\n",
    "    checkpoint_scores = checkpoint_total(grades)\n",
    "\n",
    "    # discussion total\n",
    "    discussion_scores = discussion_total(grades)\n",
    "\n",
    "    # exam total\n",
    "    col_name = ' - Max Points'\n",
    "\n",
    "    midterm_scores = grades['Midterm'] / grades['Midterm' + col_name]\n",
    "    final_scores = grades['Final'] / grades['Final' + col_name]\n",
    "    \n",
    "    return (lab_scores * 0.2) + (project_scores * 0.3) + (checkpoint_scores * 0.025) + (discussion_scores * 0.025) + (midterm_scores * 0.15) + (final_scores * 0.3)\n",
    "\n",
    "\n",
    "def final_grades(total):\n",
    "    \"\"\"\n",
    "    final_grades takes in the final course grades\n",
    "    as above and returns a Series of letter grades\n",
    "    given by the standard cutoffs.\n",
    "\n",
    "    :Example:\n",
    "    >>> out = final_grades(pd.Series([0.92, 0.81, 0.41]))\n",
    "    >>> np.all(out == ['A', 'B', 'F'])\n",
    "    True\n",
    "    \"\"\"\n",
    "\n",
    "    letter = total.where(~total.between(0.9, 1), 'A')\n",
    "    letter = letter.where(~total.between(0.8, 0.9), 'B')\n",
    "    letter = letter.where(~total.between(0.7, 0.8), 'C')\n",
    "    letter = letter.where(~total.between(0.6, 0.7), 'D')\n",
    "    letter = letter.where(~total.between(0, 0.6), 'F')\n",
    "    \n",
    "    return letter\n",
    "\n",
    "\n",
    "def letter_proportions(grades):\n",
    "    \"\"\"\n",
    "    letter_proportions takes in the dataframe grades\n",
    "    and outputs a Series that contains the proportion\n",
    "    of the class that received each grade.\n",
    "\n",
    "    :Example:\n",
    "    >>> fp = os.path.join('data', 'grades.csv')\n",
    "    >>> grades = pd.read_csv(fp)\n",
    "    >>> out = letter_proportions(grades)\n",
    "    >>> np.all(out.index == ['B', 'C', 'A', 'D', 'F'])\n",
    "    True\n",
    "    >>> out.sum() == 1.0\n",
    "    True\n",
    "    \"\"\"\n",
    "\n",
    "    total = total_points(grades)\n",
    "    letter = final_grades(total)\n",
    "    \n",
    "    distribution = letter.value_counts()\n",
    "    \n",
    "    return distribution / grades.shape[0]\n",
    "\n",
    "# ---------------------------------------------------------------------\n",
    "# Question # 8\n",
    "# ---------------------------------------------------------------------\n",
    "\n",
    "def simulate_pval(grades, N):\n",
    "    \"\"\"\n",
    "    simulate_pval takes in the number of\n",
    "    simulations N and grades and returns\n",
    "    the likelihood that the grade of sophomores\n",
    "    was no better on average than the class\n",
    "    as a whole (i.e. calculate the p-value).\n",
    "\n",
    "    :Example:\n",
    "    >>> fp = os.path.join('data', 'grades.csv')\n",
    "    >>> grades = pd.read_csv(fp)\n",
    "    >>> out = simulate_pval(grades, 100)\n",
    "    >>> 0 <= out <= 0.1\n",
    "    True\n",
    "    \"\"\"\n",
    "    \n",
    "    sophomores = grades.loc[grades['Level'] == 'SO']\n",
    "    total_s = total_points(sophomores)\n",
    "    test_statistic = total_s.mean()\n",
    "    \n",
    "    n_means = []\n",
    "    mean_grades = total_points(grades).mean()\n",
    "\n",
    "    for i in range(N):\n",
    "        sample = grades.sample(sophomores.shape[0], replace = False)\n",
    "        sample_total = total_points(sample)\n",
    "        new_avg = sample_total.mean()\n",
    "        n_means.append(new_avg)\n",
    "\n",
    "    return np.count_nonzero(np.array(n_means) >= test_statistic) / N\n",
    "\n",
    "\n",
    "# ---------------------------------------------------------------------\n",
    "# Question # 9\n",
    "# ---------------------------------------------------------------------\n",
    "\n",
    "def unwind(columns):\n",
    "    columns.values()\n",
    "    cols = []\n",
    "    \n",
    "    for i in columns.values():\n",
    "        for j in i:\n",
    "            cols.append(j)\n",
    "            \n",
    "    return cols\n",
    "\n",
    "def total_points_with_noise(grades):\n",
    "    \"\"\"\n",
    "    total_points_with_noise takes in a dataframe like grades,\n",
    "    adds noise to the assignments as described in notebook, and returns\n",
    "    the total scores of each student calculated with noisy grades.\n",
    "\n",
    "    :Example:\n",
    "    >>> fp = os.path.join('data', 'grades.csv')\n",
    "    >>> grades = pd.read_csv(fp)\n",
    "    >>> out = total_points_with_noise(grades)\n",
    "    >>> np.all((0 <= out) & (out <= 1))\n",
    "    True\n",
    "    >>> 0.7 < out.mean() < 0.9\n",
    "    True\n",
    "    \"\"\"\n",
    "\n",
    "    num_rows = grades.shape[0]\n",
    "    num_cols = grades.shape[1]\n",
    "    random_amt = pd.DataFrame(np.random.normal(0, 0.02, size=(num_rows, num_cols)))\n",
    "    \n",
    "    noise = grades.copy()\n",
    "    columns = get_assignment_names(grades)\n",
    "    n = 0\n",
    "    \n",
    "    for col in unwind(columns):\n",
    "        noise[col] = np.clip(noise[col] + random_amt[n], 0, 100)\n",
    "        n += 1\n",
    "    \n",
    "    return total_points(noise)\n",
    "\n",
    "\n",
    "# ---------------------------------------------------------------------\n",
    "# Question #10\n",
    "# ---------------------------------------------------------------------\n",
    "\n",
    "def short_answer():\n",
    "    \"\"\"\n",
    "    short_answer returns (hard-coded) answers to the\n",
    "    questions listed in the notebook. The answers should be\n",
    "    given in a list with the same order as questions.\n",
    "\n",
    "    :Example:\n",
    "    >>> out = short_answer()\n",
    "    >>> len(out) == 5\n",
    "    True\n",
    "    >>> len(out[2]) == 2\n",
    "    True\n",
    "    >>> 50 < out[2][0] < 100\n",
    "    True\n",
    "    >>> 0 < out[3] < 1\n",
    "    True\n",
    "    >>> isinstance(out[4], bool)\n",
    "    True\n",
    "    \"\"\"\n",
    "\n",
    "    return [1.0174066278123561e-05, 100, [0, 100.0], 0, True]\n",
    "\n",
    "# ---------------------------------------------------------------------\n",
    "# DO NOT TOUCH BELOW THIS LINE\n",
    "# IT'S FOR YOUR OWN BENEFIT!\n",
    "# ---------------------------------------------------------------------\n",
    "\n",
    "\n",
    "# Graded functions names! DO NOT CHANGE!\n",
    "# This dictionary provides your doctests with\n",
    "# a check that all of the questions being graded\n",
    "# exist in your code!\n",
    "\n",
    "GRADED_FUNCTIONS = {\n",
    "    'q01': ['get_assignment_names'],\n",
    "    'q02': ['projects_total'],\n",
    "    'q03': ['last_minute_submissions'],\n",
    "    'q04': ['lateness_penalty'],\n",
    "    'q05': ['process_labs'],\n",
    "    'q06': ['lab_total'],\n",
    "    'q07': ['total_points', 'final_grades', 'letter_proportions'],\n",
    "    'q08': ['simulate_pval'],\n",
    "    'q09': ['total_points_with_noise'],\n",
    "    'q10': ['short_answer']\n",
    "}\n",
    "\n",
    "\n",
    "def check_for_graded_elements():\n",
    "    \"\"\"\n",
    "    >>> check_for_graded_elements()\n",
    "    True\n",
    "    \"\"\"\n",
    "\n",
    "    for q, elts in GRADED_FUNCTIONS.items():\n",
    "        for elt in elts:\n",
    "            if elt not in globals():\n",
    "                stmt = \"YOU CHANGED A QUESTION THAT SHOULDN'T CHANGE! \\\n",
    "                In %s, part %s is missing\" %(q, elt)\n",
    "                raise Exception(stmt)\n",
    "\n",
    "    return True\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DSC 80: Project 01\n",
    "\n",
    "### Checkpoint Due Date: Thursday April 9, 11:59:59 PM (Questions 1-4)\n",
    "### Due Date: Thursday, April 16, 11:59:59 PM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grades = grades.replace({np.nan: 0})\n",
    "grades.loc[23]['lab02']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# Instructions\n",
    "\n",
    "This Jupyter Notebook contains the statements of the problems and provides code and markdown cells to display your answers to the problems.  \n",
    "* Like the lab, your coding work will be developed in the accompanying `project01.py` file, that will be imported into the current notebook. This code will be autograded.\n",
    "* **For the checkpoint, turn in questions 1-4**\n",
    "\n",
    "**Do not change the function names in the `*.py` file**\n",
    "- The functions in the `*.py` file are how your assignment is graded, and they are graded by their name. The dictionary at the end of the file (`GRADED FUNCTIONS`) contains the \"grading list\". The final function in the file allows your doctests to check that all the necessary functions exist.\n",
    "- If you changed something you weren't supposed to, just use git to revert!\n",
    "\n",
    "**Tips for developing in the .py file**:\n",
    "- Do not change the function names in the starter code; grading is done using these function names.\n",
    "- Do not change the docstrings in the functions. These are there to tell you if your work is on the right track!\n",
    "- You are **encouraged to write your own additional functions** to solve the questions! \n",
    "    - Developing in python usually consists of larger files, with many short functions.\n",
    "    - You may write your other functions in an additional `.py` file that you import in `project01.py` -- however, be sure to upload these to gradescope as well!\n",
    "- Always document your code!\n",
    "\n",
    "**Tips for testing the correctness of your answers!**\n",
    "Once you have your work saved in the .py file, you should import the `project01` to test your function out in the notebook. In the notebook you should inspect/analyze the output to assess its correctness!\n",
    "* Run your functions on the main dataset (`grades`) and ask yourself if the output *looks correct.*\n",
    "* Run your functions on very small datasets (e.g. 1-5 row table), calculate the expected response by hand, and see if the function output matches (this *is* unit-testing your code with data).\n",
    "* Run your functions on (large and small) samples of the dataset `grades` (with and without replacement). Does your code break? Or does it still run as expected."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import project01 as proj"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# The Other Side of Gradescope\n",
    "\n",
    "The file contains the grade-book from a fictional data science course with 535 students. \n",
    "\n",
    "**Note: this dataset is synthetically generated; it does not contain real student grades.**\n",
    "\n",
    "In this project, you will:\n",
    "1. clean and process the data to compute total course grades according to a fictional syllabus (below),\n",
    "2. qualitatively understand how students did in the course,\n",
    "3. understand how student grades vary with small changes in performance on each assignment.\n",
    "\n",
    "---\n",
    "\n",
    "The course syllabus is as follows:\n",
    "\n",
    "* Lab assignments \n",
    "    - Each are worth the same amount, regardless of each lab's raw point total.\n",
    "    - The lowest lab is dropped.\n",
    "    - Each lab may be revised for one week after submission for a 10% penalty, for two weeks after submission for a 20% penalty, and beyond that for a 50% penalty. Such revisions are reflected in the `Lateness` columns in the gradebook.\n",
    "    - Labs are 20% of the total grade.\n",
    "* Projects \n",
    "    - Each project consists of an autograded portion, and *possibly* a free response portion.\n",
    "    - The total points for a single project consist of the sum of the raw score of the two portions.\n",
    "    - Each are worth the same amount, regardless of each project's raw point total.\n",
    "    - Projects are 30% of the total grade.\n",
    "* Checkpoints\n",
    "    - Project checkpoints are worth 2.5% of the total grade.\n",
    "* Discussion\n",
    "    - Discussion notebooks are worth 2.5% of the total grade.\n",
    "* Exams\n",
    "    - The midterm is worth 15% of the total grade.\n",
    "    - The final is worth 30% of the total grade.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### A note on generalization\n",
    "\n",
    "You may assume that your code will only need to work on a gradebook for a class with the syllabus given above. That is, you may assume that the dataframe `grades` looks like the given one in `data/grades.csv`.\n",
    "\n",
    "However, such a class:\n",
    "1. may have a different numbers of labs, projects, discussions, and project checkpoints.\n",
    "2. may have a different number of students.\n",
    "\n",
    "You may assume the course components and the naming conventions are as given in the data file.\n",
    "\n",
    "The dataset was generated by Gradescope; you must attempt to reason about the data as given using what you know as a student who uses Gradescope.\n",
    "\n",
    "### A note on 'putting everything together'\n",
    "\n",
    "The goal of this project is to create and assess final grades for a fictional course; if anything, the process is broken down into functions for your convenience and guidance. Here are a few remarks and tips for approaching the projects:\n",
    "1. If you are having trouble figuring out what a question is asking you to do, look at the big picture and try to understand what the current step is doing to contribute to this big picture. This may clarify what's being asked!\n",
    "1. These questions intentionally build off of each other and the final result matters! In fact, you can 'get a question correct', but only receive partial credit on it because a previous answer was wrong.\n",
    "    - Credit for a question will typically receive partial credit based on *how close* your answer is to correct (as well as some credit for a solution in the correct form). \n",
    "    - You should try to assess your answer to each question based on what you understand of the data. This might involve writing extensive code (that isn't turned in) just to check your work! Suggestions on checking your work are given in the assignment, but you should also think of your own ways of checking your work.\n",
    "    - As you do this project, think about the data from the perspective of the student (which should be easy to do!)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "grades_fp = os.path.join('data', 'grades.csv')\n",
    "grades = pd.read_csv(grades_fp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Getting started: enumerating the assignments\n",
    "\n",
    "First, you will list all the 'assignment names' and what part of the syllabus to which they belong.\n",
    "\n",
    "**Question 1:**\n",
    "\n",
    "Create a function `get_assignment_names` that takes in a dataframe like `grades` and returns a dictionary with the following structure:\n",
    "- The keys are the general areas of the syllabus: `lab, project, midterm, final, disc, checkpoint`\n",
    "- The values are lists that contain the assignment names of that type. For example the lab assignments all have names of the form `labXX` where `XX` is a zero-padded two digit number. See the doctests for more details."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_assignment_names(df):\n",
    "    \n",
    "    names = {'lab':[], 'project': [], 'midterm':['Midterm'], 'final':['Final'], 'disc':[], 'checkpoint':[]}\n",
    "    \n",
    "    \n",
    "    #is it always up to 10?\n",
    "    for col in df.columns:\n",
    "        if ('lab' in col) and (len(col) == 5):\n",
    "            names['lab'].append(col)\n",
    "        elif ('project' in col) and (len(col) == 9):\n",
    "            names['project'].append(col)\n",
    "        elif ('discussion' in col) and (len(col) == 12):\n",
    "            names['disc'].append(col)\n",
    "        elif ('checkpoint' in col) and (len(col) == 22):\n",
    "            names['checkpoint'].append(col)\n",
    "            \n",
    "    return names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PID</th>\n",
       "      <th>College</th>\n",
       "      <th>Level</th>\n",
       "      <th>lab01</th>\n",
       "      <th>lab01 - Max Points</th>\n",
       "      <th>lab01 - Lateness (H:M:S)</th>\n",
       "      <th>lab02</th>\n",
       "      <th>lab02 - Max Points</th>\n",
       "      <th>lab02 - Lateness (H:M:S)</th>\n",
       "      <th>project01</th>\n",
       "      <th>...</th>\n",
       "      <th>discussion07 - Lateness (H:M:S)</th>\n",
       "      <th>discussion08</th>\n",
       "      <th>discussion08 - Max Points</th>\n",
       "      <th>discussion08 - Lateness (H:M:S)</th>\n",
       "      <th>discussion09</th>\n",
       "      <th>discussion09 - Max Points</th>\n",
       "      <th>discussion09 - Lateness (H:M:S)</th>\n",
       "      <th>discussion10</th>\n",
       "      <th>discussion10 - Max Points</th>\n",
       "      <th>discussion10 - Lateness (H:M:S)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>A14721419</td>\n",
       "      <td>SI</td>\n",
       "      <td>JR</td>\n",
       "      <td>99.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>00:00:00</td>\n",
       "      <td>86.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>00:00:00</td>\n",
       "      <td>75.0</td>\n",
       "      <td>...</td>\n",
       "      <td>00:00:00</td>\n",
       "      <td>10.0</td>\n",
       "      <td>10</td>\n",
       "      <td>00:00:00</td>\n",
       "      <td>10.0</td>\n",
       "      <td>10</td>\n",
       "      <td>780:01:28</td>\n",
       "      <td>10.0</td>\n",
       "      <td>10</td>\n",
       "      <td>00:00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>A14883274</td>\n",
       "      <td>TH</td>\n",
       "      <td>JR</td>\n",
       "      <td>98.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>00:00:00</td>\n",
       "      <td>52.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>00:00:00</td>\n",
       "      <td>53.0</td>\n",
       "      <td>...</td>\n",
       "      <td>669:12:21</td>\n",
       "      <td>7.0</td>\n",
       "      <td>10</td>\n",
       "      <td>00:00:00</td>\n",
       "      <td>7.0</td>\n",
       "      <td>10</td>\n",
       "      <td>00:00:00</td>\n",
       "      <td>8.0</td>\n",
       "      <td>10</td>\n",
       "      <td>00:00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>A14164800</td>\n",
       "      <td>SI</td>\n",
       "      <td>SR</td>\n",
       "      <td>86.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>00:00:00</td>\n",
       "      <td>45.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>00:00:00</td>\n",
       "      <td>44.0</td>\n",
       "      <td>...</td>\n",
       "      <td>00:00:00</td>\n",
       "      <td>6.0</td>\n",
       "      <td>10</td>\n",
       "      <td>00:04:51</td>\n",
       "      <td>6.0</td>\n",
       "      <td>10</td>\n",
       "      <td>00:00:00</td>\n",
       "      <td>7.0</td>\n",
       "      <td>10</td>\n",
       "      <td>00:00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>A14847419</td>\n",
       "      <td>TH</td>\n",
       "      <td>JR</td>\n",
       "      <td>100.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>00:00:00</td>\n",
       "      <td>100.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>00:00:00</td>\n",
       "      <td>78.0</td>\n",
       "      <td>...</td>\n",
       "      <td>00:00:00</td>\n",
       "      <td>10.0</td>\n",
       "      <td>10</td>\n",
       "      <td>00:00:00</td>\n",
       "      <td>10.0</td>\n",
       "      <td>10</td>\n",
       "      <td>00:00:00</td>\n",
       "      <td>10.0</td>\n",
       "      <td>10</td>\n",
       "      <td>00:00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>A14162943</td>\n",
       "      <td>SI</td>\n",
       "      <td>JR</td>\n",
       "      <td>66.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>00:00:00</td>\n",
       "      <td>33.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>00:00:00</td>\n",
       "      <td>42.0</td>\n",
       "      <td>...</td>\n",
       "      <td>00:00:00</td>\n",
       "      <td>5.0</td>\n",
       "      <td>10</td>\n",
       "      <td>00:00:00</td>\n",
       "      <td>5.0</td>\n",
       "      <td>10</td>\n",
       "      <td>00:00:00</td>\n",
       "      <td>6.0</td>\n",
       "      <td>10</td>\n",
       "      <td>00:00:00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 100 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         PID College Level  lab01  lab01 - Max Points  \\\n",
       "0  A14721419      SI    JR   99.0               100.0   \n",
       "1  A14883274      TH    JR   98.0               100.0   \n",
       "2  A14164800      SI    SR   86.0               100.0   \n",
       "3  A14847419      TH    JR  100.0               100.0   \n",
       "4  A14162943      SI    JR   66.0               100.0   \n",
       "\n",
       "  lab01 - Lateness (H:M:S)  lab02  lab02 - Max Points  \\\n",
       "0                 00:00:00   86.0               100.0   \n",
       "1                 00:00:00   52.0               100.0   \n",
       "2                 00:00:00   45.0               100.0   \n",
       "3                 00:00:00  100.0               100.0   \n",
       "4                 00:00:00   33.0               100.0   \n",
       "\n",
       "  lab02 - Lateness (H:M:S)  project01  ...  discussion07 - Lateness (H:M:S)  \\\n",
       "0                 00:00:00       75.0  ...                         00:00:00   \n",
       "1                 00:00:00       53.0  ...                        669:12:21   \n",
       "2                 00:00:00       44.0  ...                         00:00:00   \n",
       "3                 00:00:00       78.0  ...                         00:00:00   \n",
       "4                 00:00:00       42.0  ...                         00:00:00   \n",
       "\n",
       "  discussion08  discussion08 - Max Points  discussion08 - Lateness (H:M:S)  \\\n",
       "0         10.0                         10                         00:00:00   \n",
       "1          7.0                         10                         00:00:00   \n",
       "2          6.0                         10                         00:04:51   \n",
       "3         10.0                         10                         00:00:00   \n",
       "4          5.0                         10                         00:00:00   \n",
       "\n",
       "  discussion09  discussion09 - Max Points  discussion09 - Lateness (H:M:S)  \\\n",
       "0         10.0                         10                        780:01:28   \n",
       "1          7.0                         10                         00:00:00   \n",
       "2          6.0                         10                         00:00:00   \n",
       "3         10.0                         10                         00:00:00   \n",
       "4          5.0                         10                         00:00:00   \n",
       "\n",
       "  discussion10  discussion10 - Max Points  discussion10 - Lateness (H:M:S)  \n",
       "0         10.0                         10                         00:00:00  \n",
       "1          8.0                         10                         00:00:00  \n",
       "2          7.0                         10                         00:00:00  \n",
       "3         10.0                         10                         00:00:00  \n",
       "4          6.0                         10                         00:00:00  \n",
       "\n",
       "[5 rows x 100 columns]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grades.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.isnull(grades.loc[64].project01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "nan"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grades.loc[62].project01"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Computing project grades\n",
    "\n",
    "**Question 2**\n",
    "\n",
    "Compute the total score for the project portion of the course according to the syllabus. Create a function `projects_total` that takes in `grades` and computes the total project grade for the quarter according to the syllabus. The output Series should contain values between 0 and 1.\n",
    "\n",
    "*Note*: Don't forget to properly handle students who didn't turn in assignments! (Use your experience and common sense).\n",
    "\n",
    "*Note:* To check your work, try (1) calculating the score for a few types of students by hand, and (2) calculate the statistics for the class performance on each individual course project, making sure they look reasonable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#need to handle students who don't turn it in\n",
    "def projects_total(grades):\n",
    "    \n",
    "    names = get_assignment_names(grades)\n",
    "\n",
    "    copy = grades.copy()\n",
    "    project_scores = [] \n",
    "    \n",
    "    #loop thru projects\n",
    "    for project_name in names['project']:\n",
    "        \n",
    "        #check if theres a free response\n",
    "        if project_name + '_free_response' in copy.columns:\n",
    "            project_fr_name = project_name + '_free_response'\n",
    "        else:\n",
    "            project_fr_name = None\n",
    "            \n",
    "        #handle NaN values to get 0 score\n",
    "        copy[project_name] = copy[project_name].fillna(0)\n",
    "        if project_fr_name != None: #free response exists\n",
    "            copy[project_fr_name] = copy[project_fr_name].fillna(0)\n",
    "            \n",
    "            \n",
    "        #numerator\n",
    "        if project_fr_name != None: #free response exists\n",
    "            points = copy[project_name] + copy[project_fr_name]\n",
    "        else:\n",
    "            points = copy[project_name]\n",
    "        \n",
    "        #denominator\n",
    "        if project_fr_name != None: #free response exists\n",
    "            total_points = copy[project_name + ' - Max Points'] + copy[project_fr_name + ' - Max Points']\n",
    "        else:\n",
    "            total_points = copy[project_name + ' - Max Points']\n",
    "            \n",
    "        #compute scores for this project\n",
    "        score = points/total_points\n",
    "        project_scores.append(score)\n",
    "        \n",
    "    \n",
    "    total_scores = sum(project_scores) / len(names['project']) #divided by number of projects\n",
    "    return total_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0      0.900000\n",
       "1      0.759333\n",
       "2      0.673333\n",
       "3      0.952667\n",
       "4      0.718667\n",
       "         ...   \n",
       "530    0.949333\n",
       "531    0.846667\n",
       "532    0.837333\n",
       "533    0.797333\n",
       "534    0.948000\n",
       "Length: 535, dtype: float64"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "projects_total(grades)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out = projects_total(grades)\n",
    "#np.all((0 <= out) & (out <= 1))\n",
    "\n",
    "0.7 < out.mean() < 0.9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Computing lab grades\n",
    "\n",
    "Now, you will clean and process the lab grades, which is a little more complicated. To do this, you will develop functions that:\n",
    "- 'normalize' the grades, \n",
    "- adjust for late submissions, \n",
    "- drop the lowest lab grade, and \n",
    "- creates a total lab score for each student."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question 3**\n",
    "\n",
    "Unfortunately, Gradescope sometimes experiences a delay in registering when an assignment is submitted during \"periods of heavy usage\" (i.e. near a submission deadline). You need to assess when a student's assignment was actually turned in on time, even if Gradescope did not process it in time. To do this, it is helpful to know:\n",
    "* Every late submission has to be submitted by a TA (late submissions are turned off).\n",
    "* TAs never submitted a late assignment \"just after\" the deadline. \n",
    "* The deadlines were at midnight and students had to come to staff hours to late-submit their assignment.\n",
    "\n",
    "Create a function `last_minute_submissions` that takes in the dataframe `grades` and outputs the number of submissions on each assignment that were turned in on time by the student, yet marked 'late' by Gradescope. See the doctest for more details.\n",
    "\n",
    "*Note:* You have to figure out what truly is a late submission by looking at the data and understanding the facts about the data generating process above. There is some ambiguity in finding which submissions are truly late; you will *make a best guess for a threshold* by looking at this dataset. This question is about 'cleaning' a messy 'data recording process'."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def last_minute_submissions(grades):\n",
    "    \n",
    "    late_tag = ' - Lateness (H:M:S)'\n",
    "        \n",
    "    names = get_assignment_names(grades)\n",
    "    \n",
    "    late_submissions = {}\n",
    "    \n",
    "    for lab in names['lab']:\n",
    "        \n",
    "        gradescope_late = grades.copy()\n",
    "        \n",
    "        gradescope_late = gradescope_late[gradescope_late[lab + late_tag] != '00:00:00']\n",
    "    \n",
    "        gradescope_late[lab + late_tag] = gradescope_late[lab + late_tag].str.slice(stop = 2)\n",
    "                \n",
    "        gradescope_late[lab + late_tag] = gradescope_late[lab + late_tag].astype(int)\n",
    "        \n",
    "        error_late = gradescope_late.loc[gradescope_late[lab + late_tag] < 9]\n",
    "        \n",
    "        late_submissions[lab] = len(error_late)\n",
    "        \n",
    "    series = pd.Series(late_submissions)  \n",
    "    return series"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fp = os.path.join('data', 'grades.csv')\n",
    "grades = pd.read_csv(fp)\n",
    "out = last_minute_submissions(grades)\n",
    "(out > 0).sum()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question 4**\n",
    "\n",
    "Now you need to adjust the lab grades for late submissions -- however, you need to take into account your investigation in the previous question, since students shouldn't be penalized by a bug in Gradescope!\n",
    "\n",
    "Create a function `lateness_penalty` that takes in a 'Lateness' column and returns a column of penalties (represented by the values `1.0,0.9,0.8,0.5` according to the syllabus). Only *truly* late submissions should be counted as late.\n",
    "\n",
    "*Note*: For the purpose of this project, we will only be calculating lateness for labs. There is no penalty for lateness for projects, discussions, nor checkpoints."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lateness_penalty(col):\n",
    "    \n",
    "    #make series, starting with all 1.0 penalties\n",
    "    penalties = pd.Series(1.0, index = col.index)\n",
    "\n",
    "    #convert times to numbers\n",
    "    col1 = col.str.contains('00:00:00')\n",
    "    ontime_gc = col1[col1].index    \n",
    "    col = col.drop(index = ontime_gc)\n",
    "    \n",
    "    hours = col.str.split(':', 1, True)\n",
    "    hours[0] = hours[0].astype(int)\n",
    "    hours[1] = hours[1].str.contains('00:00')\n",
    "    hours[0] = hours[0] + ~hours[1]\n",
    "    hours = hours[0]\n",
    "\n",
    "    #late 1 week (before 9 AM doesn't count)\n",
    "    week_late = hours[hours.between(9, 168)]\n",
    "    week_late_indices = week_late.index.values\n",
    "    penalties[week_late_indices] = 0.9\n",
    "\n",
    "    #late 2 weeks\n",
    "    two_weeks = hours[hours.between(169, 336)]\n",
    "    two_weeks_indices = two_weeks.index.values\n",
    "    penalties[two_weeks_indices] = 0.8\n",
    "\n",
    "    #beyond\n",
    "    beyond = hours[hours >= 337]\n",
    "    beyond_indices = beyond.index.values\n",
    "    penalties[beyond_indices] = 0.5\n",
    "\n",
    "    return penalties"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'hour' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-16-d6a5fe89942b>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mfp\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mos\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'data'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'grades.csv'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[0mcol\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfp\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'lab01 - Lateness (H:M:S)'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m \u001b[0mout\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlateness_penalty\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcol\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      4\u001b[0m \u001b[0mset\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mout\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0munique\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m<=\u001b[0m \u001b[1;33m{\u001b[0m\u001b[1;36m1.0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m0.9\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m0.8\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m0.5\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-15-38bc781bdae3>\u001b[0m in \u001b[0;36mlateness_penalty\u001b[1;34m(col)\u001b[0m\n\u001b[0;32m      6\u001b[0m     \u001b[1;31m#convert times to numbers\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m     \u001b[0mhours\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcol\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstr\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mslice\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstop\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 8\u001b[1;33m     \u001b[0mhours\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mhour\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mint\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      9\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     10\u001b[0m     \u001b[1;31m#late 1 week (before 9 hours doesnt count)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'hour' is not defined"
     ]
    }
   ],
   "source": [
    "fp = os.path.join('data', 'grades.csv')\n",
    "col = pd.read_csv(fp)['lab01 - Lateness (H:M:S)']\n",
    "out = lateness_penalty(col)\n",
    "set(out.unique()) <= {1.0, 0.9, 0.8, 0.5}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<ipython-input-17-f5fd4790c37f>, line 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  File \u001b[1;32m\"<ipython-input-17-f5fd4790c37f>\"\u001b[1;36m, line \u001b[1;32m1\u001b[0m\n\u001b[1;33m    1 week (168 hrs) - 10%\u001b[0m\n\u001b[1;37m         ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "1 week (168 hrs) - 10%\n",
    "2 weeks (169-336 hrs) - 20%\n",
    "beyond (337+hrs) - 50%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "col = grades['lab01 - Lateness (H:M:S)']\n",
    "\n",
    "#make series, starting with all 1.0 penalties\n",
    "penalties = pd.Series(1.0, index = col.index)\n",
    "\n",
    "#convert times to numbers\n",
    "hours = col.str.slice(stop = 2)\n",
    "hours = hour.astype(int)\n",
    "\n",
    "#late 1 week (before 9 hours doesnt count)\n",
    "week_late = hours[hours.between(9, 168)]\n",
    "week_late_indices = week_late.index.values\n",
    "penalties[week_late_indices] = 0.9\n",
    "\n",
    "#late 2 weeks\n",
    "two_weeks = hours[hours.between(169, 336)]\n",
    "two_weeks_indices = two_weeks.index.values\n",
    "penalties[two_weeks_indices] = 0.8\n",
    "\n",
    "#beyond\n",
    "beyond = hours[hours >= 337]\n",
    "beyond_indices = beyond.index.values\n",
    "penalties[beyond_indices] = 0.5\n",
    "\n",
    "penalties\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0     10\n",
       "1    100\n",
       "2    100\n",
       "3     10\n",
       "4     10\n",
       "5    100\n",
       "dtype: int64"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_col = pd.Series([10, 10, 10, 10, 10, 10], index = [0, 1, 2, 3, 4, 5])\n",
    "i_to_replace = np.array([1, 2, 5])\n",
    "replaced = 100\n",
    "test_col[i_to_replace] = 100\n",
    "test_col\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question 5**\n",
    "\n",
    "Create a function `process_labs` that takes in a dataframe like `grades` and returns a dataframe of processed lab scores. The output should:\n",
    "* share the same index as `grades`,\n",
    "* have columns given by the lab assignment names (e.g. `lab01,...lab10`)\n",
    "* have values representing the lab grades for each assignment, adjusted for Lateness and scaled to a score between 0 and 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'>' not supported between instances of 'str' and 'int'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-86-4093ae69fd4d>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mseries\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mgrades\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'lab01'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mindex_to_replace\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mseries\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mseries\u001b[0m \u001b[1;33m>\u001b[0m \u001b[1;36m90\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m \u001b[1;31m#series.replace(index_to_replace, 'A')\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;31m#series[series > 90]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;31m#series.loc[index_to_replace] = 'A'\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\pandas\\core\\ops\\__init__.py\u001b[0m in \u001b[0;36mwrapper\u001b[1;34m(self, other, axis)\u001b[0m\n\u001b[0;32m   1227\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1228\u001b[0m             \u001b[1;32mwith\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0merrstate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mall\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"ignore\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1229\u001b[1;33m                 \u001b[0mres\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mna_op\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mother\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1230\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mis_scalar\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mres\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1231\u001b[0m                 raise TypeError(\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\pandas\\core\\ops\\__init__.py\u001b[0m in \u001b[0;36mna_op\u001b[1;34m(x, y)\u001b[0m\n\u001b[0;32m   1089\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1090\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mis_object_dtype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1091\u001b[1;33m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_comp_method_OBJECT_ARRAY\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mop\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1092\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1093\u001b[0m         \u001b[1;32melif\u001b[0m \u001b[0mis_datetimelike_v_numeric\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\pandas\\core\\ops\\__init__.py\u001b[0m in \u001b[0;36m_comp_method_OBJECT_ARRAY\u001b[1;34m(op, x, y)\u001b[0m\n\u001b[0;32m   1067\u001b[0m         \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlibops\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvec_compare\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mop\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1068\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1069\u001b[1;33m         \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlibops\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mscalar_compare\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mop\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1070\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1071\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\ops.pyx\u001b[0m in \u001b[0;36mpandas._libs.ops.scalar_compare\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: '>' not supported between instances of 'str' and 'int'"
     ]
    }
   ],
   "source": [
    "series = grades['lab01']\n",
    "index_to_replace = series[series > 90].index.values\n",
    "#series.replace(index_to_replace, 'A')\n",
    "#series[series > 90]\n",
    "#series.loc[index_to_replace] = 'A'\n",
    "index_to_replace\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_labs(grades):\n",
    "    names = get_assignment_names(grades)\n",
    "    processed_labs = pd.DataFrame()\n",
    "\n",
    "    for lab in names['lab']:\n",
    "        lab_grades = grades[lab] / grades[lab + ' - Max Points']\n",
    "        lab_times = grades[lab + ' - Lateness (H:M:S)']\n",
    "        lab_grades_adjusted = (lateness_penalty(lab_times) * lab_grades) \n",
    "        processed_labs[lab] = lab_grades_adjusted\n",
    "\n",
    "    return processed_labs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fp = os.path.join('data', 'grades.csv')\n",
    "grades = pd.read_csv(fp)\n",
    "out = process_labs(grades)\n",
    "np.all((0.65 <= out.mean()) & (out.mean() <= 0.90))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "42.39463601532567"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grades['lab09'].mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question 6**\n",
    "\n",
    "Create a function `lab_total` that takes in dataframe of processed assignments (like the output of Question 5) and computes the total lab grade for each student according to the syllabus (returning a Series). Your answers should be proportions between 0 and 1. For example, if there are only 3 labs, and a student received scores of {80%,90%,100%}, then the total score would be 0.95.\n",
    "\n",
    "*Note*: Don't forget to properly handle students who didn't turn in assignments! (Use your experience and common sense)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PID</th>\n",
       "      <th>College</th>\n",
       "      <th>Level</th>\n",
       "      <th>lab01</th>\n",
       "      <th>lab01 - Max Points</th>\n",
       "      <th>lab01 - Lateness (H:M:S)</th>\n",
       "      <th>lab02</th>\n",
       "      <th>lab02 - Max Points</th>\n",
       "      <th>lab02 - Lateness (H:M:S)</th>\n",
       "      <th>project01</th>\n",
       "      <th>...</th>\n",
       "      <th>discussion07 - Lateness (H:M:S)</th>\n",
       "      <th>discussion08</th>\n",
       "      <th>discussion08 - Max Points</th>\n",
       "      <th>discussion08 - Lateness (H:M:S)</th>\n",
       "      <th>discussion09</th>\n",
       "      <th>discussion09 - Max Points</th>\n",
       "      <th>discussion09 - Lateness (H:M:S)</th>\n",
       "      <th>discussion10</th>\n",
       "      <th>discussion10 - Max Points</th>\n",
       "      <th>discussion10 - Lateness (H:M:S)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>A14721419</td>\n",
       "      <td>SI</td>\n",
       "      <td>JR</td>\n",
       "      <td>99.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>00:00:00</td>\n",
       "      <td>86.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>00:00:00</td>\n",
       "      <td>75.0</td>\n",
       "      <td>...</td>\n",
       "      <td>00:00:00</td>\n",
       "      <td>10.0</td>\n",
       "      <td>10</td>\n",
       "      <td>00:00:00</td>\n",
       "      <td>10.0</td>\n",
       "      <td>10</td>\n",
       "      <td>780:01:28</td>\n",
       "      <td>10.0</td>\n",
       "      <td>10</td>\n",
       "      <td>00:00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>A14883274</td>\n",
       "      <td>TH</td>\n",
       "      <td>JR</td>\n",
       "      <td>98.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>00:00:00</td>\n",
       "      <td>52.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>00:00:00</td>\n",
       "      <td>53.0</td>\n",
       "      <td>...</td>\n",
       "      <td>669:12:21</td>\n",
       "      <td>7.0</td>\n",
       "      <td>10</td>\n",
       "      <td>00:00:00</td>\n",
       "      <td>7.0</td>\n",
       "      <td>10</td>\n",
       "      <td>00:00:00</td>\n",
       "      <td>8.0</td>\n",
       "      <td>10</td>\n",
       "      <td>00:00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>A14164800</td>\n",
       "      <td>SI</td>\n",
       "      <td>SR</td>\n",
       "      <td>86.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>00:00:00</td>\n",
       "      <td>45.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>00:00:00</td>\n",
       "      <td>44.0</td>\n",
       "      <td>...</td>\n",
       "      <td>00:00:00</td>\n",
       "      <td>6.0</td>\n",
       "      <td>10</td>\n",
       "      <td>00:04:51</td>\n",
       "      <td>6.0</td>\n",
       "      <td>10</td>\n",
       "      <td>00:00:00</td>\n",
       "      <td>7.0</td>\n",
       "      <td>10</td>\n",
       "      <td>00:00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>A14847419</td>\n",
       "      <td>TH</td>\n",
       "      <td>JR</td>\n",
       "      <td>100.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>00:00:00</td>\n",
       "      <td>100.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>00:00:00</td>\n",
       "      <td>78.0</td>\n",
       "      <td>...</td>\n",
       "      <td>00:00:00</td>\n",
       "      <td>10.0</td>\n",
       "      <td>10</td>\n",
       "      <td>00:00:00</td>\n",
       "      <td>10.0</td>\n",
       "      <td>10</td>\n",
       "      <td>00:00:00</td>\n",
       "      <td>10.0</td>\n",
       "      <td>10</td>\n",
       "      <td>00:00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>A14162943</td>\n",
       "      <td>SI</td>\n",
       "      <td>JR</td>\n",
       "      <td>66.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>00:00:00</td>\n",
       "      <td>33.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>00:00:00</td>\n",
       "      <td>42.0</td>\n",
       "      <td>...</td>\n",
       "      <td>00:00:00</td>\n",
       "      <td>5.0</td>\n",
       "      <td>10</td>\n",
       "      <td>00:00:00</td>\n",
       "      <td>5.0</td>\n",
       "      <td>10</td>\n",
       "      <td>00:00:00</td>\n",
       "      <td>6.0</td>\n",
       "      <td>10</td>\n",
       "      <td>00:00:00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 100 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         PID College Level  lab01  lab01 - Max Points  \\\n",
       "0  A14721419      SI    JR   99.0               100.0   \n",
       "1  A14883274      TH    JR   98.0               100.0   \n",
       "2  A14164800      SI    SR   86.0               100.0   \n",
       "3  A14847419      TH    JR  100.0               100.0   \n",
       "4  A14162943      SI    JR   66.0               100.0   \n",
       "\n",
       "  lab01 - Lateness (H:M:S)  lab02  lab02 - Max Points  \\\n",
       "0                 00:00:00   86.0               100.0   \n",
       "1                 00:00:00   52.0               100.0   \n",
       "2                 00:00:00   45.0               100.0   \n",
       "3                 00:00:00  100.0               100.0   \n",
       "4                 00:00:00   33.0               100.0   \n",
       "\n",
       "  lab02 - Lateness (H:M:S)  project01  ...  discussion07 - Lateness (H:M:S)  \\\n",
       "0                 00:00:00       75.0  ...                         00:00:00   \n",
       "1                 00:00:00       53.0  ...                        669:12:21   \n",
       "2                 00:00:00       44.0  ...                         00:00:00   \n",
       "3                 00:00:00       78.0  ...                         00:00:00   \n",
       "4                 00:00:00       42.0  ...                         00:00:00   \n",
       "\n",
       "  discussion08  discussion08 - Max Points  discussion08 - Lateness (H:M:S)  \\\n",
       "0         10.0                         10                         00:00:00   \n",
       "1          7.0                         10                         00:00:00   \n",
       "2          6.0                         10                         00:04:51   \n",
       "3         10.0                         10                         00:00:00   \n",
       "4          5.0                         10                         00:00:00   \n",
       "\n",
       "  discussion09  discussion09 - Max Points  discussion09 - Lateness (H:M:S)  \\\n",
       "0         10.0                         10                        780:01:28   \n",
       "1          7.0                         10                         00:00:00   \n",
       "2          6.0                         10                         00:00:00   \n",
       "3         10.0                         10                         00:00:00   \n",
       "4          5.0                         10                         00:00:00   \n",
       "\n",
       "  discussion10  discussion10 - Max Points  discussion10 - Lateness (H:M:S)  \n",
       "0         10.0                         10                         00:00:00  \n",
       "1          8.0                         10                         00:00:00  \n",
       "2          7.0                         10                         00:00:00  \n",
       "3         10.0                         10                         00:00:00  \n",
       "4          6.0                         10                         00:00:00  \n",
       "\n",
       "[5 rows x 100 columns]"
      ]
     },
     "execution_count": 187,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grades.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#in sophs: labs 3, 5, 7, 8\n",
    "#in grades.head(): labs 1, 2, 5, 8, 9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [],
   "source": [
    "fp = os.path.join('data', 'grades.csv')\n",
    "grades = pd.read_csv(fp) 3, 5, 7, 8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "0",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\pandas\\core\\indexes\\base.py\u001b[0m in \u001b[0;36mget_loc\u001b[1;34m(self, key, method, tolerance)\u001b[0m\n\u001b[0;32m   2896\u001b[0m             \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2897\u001b[1;33m                 \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2898\u001b[0m             \u001b[1;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: 0",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-193-3e7859eed7c1>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0msophs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mgrades\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mgrades\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'Level'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m'SO'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlateness_penalty\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msophs\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'lab03 - Lateness (H:M:S)'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-103-9f8afaa0f2e4>\u001b[0m in \u001b[0;36mlateness_penalty\u001b[1;34m(col)\u001b[0m\n\u001b[0;32m    178\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    179\u001b[0m     \u001b[0mhours\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcol\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstr\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m':'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 180\u001b[1;33m     \u001b[0mhours\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mhours\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mint\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    181\u001b[0m     \u001b[0mhours\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mhours\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstr\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcontains\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'00:00'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    182\u001b[0m     \u001b[0mhours\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mhours\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;33m~\u001b[0m\u001b[0mhours\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\pandas\\core\\frame.py\u001b[0m in \u001b[0;36m__getitem__\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   2978\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnlevels\u001b[0m \u001b[1;33m>\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2979\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_getitem_multilevel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2980\u001b[1;33m             \u001b[0mindexer\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2981\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mis_integer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mindexer\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2982\u001b[0m                 \u001b[0mindexer\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mindexer\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\pandas\\core\\indexes\\base.py\u001b[0m in \u001b[0;36mget_loc\u001b[1;34m(self, key, method, tolerance)\u001b[0m\n\u001b[0;32m   2897\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2898\u001b[0m             \u001b[1;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2899\u001b[1;33m                 \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_maybe_cast_indexer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2900\u001b[0m         \u001b[0mindexer\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_indexer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmethod\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mmethod\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtolerance\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtolerance\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2901\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mindexer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mndim\u001b[0m \u001b[1;33m>\u001b[0m \u001b[1;36m1\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0mindexer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msize\u001b[0m \u001b[1;33m>\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: 0"
     ]
    }
   ],
   "source": [
    "sophs = grades[grades['Level'] == 'SO']\n",
    "x = lateness_penalty(sophs['lab03 - Lateness (H:M:S)'])\n",
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "unsupported operand type(s) for /: 'str' and 'float'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-192-0222363480ba>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[1;34m'asdf'\u001b[0m \u001b[1;33m/\u001b[0m \u001b[1;36m12.3\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m: unsupported operand type(s) for /: 'str' and 'float'"
     ]
    }
   ],
   "source": [
    "'asdf' / 12.3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "20     0\n",
       "27     0\n",
       "60     0\n",
       "64     0\n",
       "80     0\n",
       "83     0\n",
       "91     0\n",
       "92     0\n",
       "96     0\n",
       "97     0\n",
       "99     0\n",
       "111    0\n",
       "121    0\n",
       "155    0\n",
       "157    0\n",
       "161    0\n",
       "172    0\n",
       "173    0\n",
       "188    0\n",
       "204    0\n",
       "209    0\n",
       "225    0\n",
       "245    0\n",
       "246    0\n",
       "254    0\n",
       "274    0\n",
       "290    0\n",
       "299    0\n",
       "307    0\n",
       "312    0\n",
       "317    0\n",
       "320    0\n",
       "321    0\n",
       "323    0\n",
       "327    0\n",
       "330    0\n",
       "334    0\n",
       "364    0\n",
       "366    0\n",
       "367    0\n",
       "375    0\n",
       "380    0\n",
       "383    0\n",
       "387    0\n",
       "388    0\n",
       "395    0\n",
       "409    0\n",
       "417    0\n",
       "433    0\n",
       "434    0\n",
       "441    0\n",
       "473    0\n",
       "477    0\n",
       "487    0\n",
       "490    0\n",
       "505    0\n",
       "515    0\n",
       "520    0\n",
       "531    0\n",
       "Name: 0, dtype: int32"
      ]
     },
     "execution_count": 194,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "col = sophs['lab03 - Lateness (H:M:S)']\n",
    "hours = col.str.split(':', 1, True)\n",
    "hours[0] = hours[0].astype(int)\n",
    "hours[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Putting it together\n",
    "\n",
    "**Question 7**\n",
    "\n",
    "Finally, you need to create the final course grades. To do this, you will add up the total of each course component according to the weights given in the syllabus. \n",
    "\n",
    "* Create a function `total_points` that takes in `grades` and returns the final course grades according to the syllabus. Course grades should be proportions between zero and one.\n",
    "* Create a function `final_grades` that takes in the final course grades as above and returns a Series of letter grades given by the standard cutoffs (`A >= .90`, `.90 > B >= .80`, `.80 > C >= .70`, `.70 > D >= .60`, `.60 > F`). You should not use rounding to determining the letter grades.\n",
    "* Create a function `letter_proportions` which takes in the dataframe `grades` and outputs a Series that contains the proportion of the class that received each grade. (This question requires you to put everything together).\n",
    "* The indices should be ordered by the proportion of the class that receives that grade, from largest to smallest.\n",
    "\n",
    "*Note 1*: Don't repeat yourself when computing the checkpoint and discussion portions of the course.\n",
    "\n",
    "*Note 2*: Only the lab portion of the course accounts for late assignments; you may assume all assignments in other portions are turned in without penalty.\n",
    "\n",
    "*Note 3*: These values should add up to exactly 1.0. If you are getting something close such as 0.99999, that means there is a slight issue with your code from above. \n",
    "\n",
    "To check your work, verify the course grade distribution and relevant statistics! Do the work by hand for a few students."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PID</th>\n",
       "      <th>College</th>\n",
       "      <th>Level</th>\n",
       "      <th>lab01</th>\n",
       "      <th>lab01 - Max Points</th>\n",
       "      <th>lab01 - Lateness (H:M:S)</th>\n",
       "      <th>lab02</th>\n",
       "      <th>lab02 - Max Points</th>\n",
       "      <th>lab02 - Lateness (H:M:S)</th>\n",
       "      <th>project01</th>\n",
       "      <th>...</th>\n",
       "      <th>discussion07 - Lateness (H:M:S)</th>\n",
       "      <th>discussion08</th>\n",
       "      <th>discussion08 - Max Points</th>\n",
       "      <th>discussion08 - Lateness (H:M:S)</th>\n",
       "      <th>discussion09</th>\n",
       "      <th>discussion09 - Max Points</th>\n",
       "      <th>discussion09 - Lateness (H:M:S)</th>\n",
       "      <th>discussion10</th>\n",
       "      <th>discussion10 - Max Points</th>\n",
       "      <th>discussion10 - Lateness (H:M:S)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>A14721419</td>\n",
       "      <td>SI</td>\n",
       "      <td>JR</td>\n",
       "      <td>99.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>00:00:00</td>\n",
       "      <td>86.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>00:00:00</td>\n",
       "      <td>75.0</td>\n",
       "      <td>...</td>\n",
       "      <td>00:00:00</td>\n",
       "      <td>10.0</td>\n",
       "      <td>10</td>\n",
       "      <td>00:00:00</td>\n",
       "      <td>10.0</td>\n",
       "      <td>10</td>\n",
       "      <td>780:01:28</td>\n",
       "      <td>10.0</td>\n",
       "      <td>10</td>\n",
       "      <td>00:00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>A14883274</td>\n",
       "      <td>TH</td>\n",
       "      <td>JR</td>\n",
       "      <td>98.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>00:00:00</td>\n",
       "      <td>52.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>00:00:00</td>\n",
       "      <td>53.0</td>\n",
       "      <td>...</td>\n",
       "      <td>669:12:21</td>\n",
       "      <td>7.0</td>\n",
       "      <td>10</td>\n",
       "      <td>00:00:00</td>\n",
       "      <td>7.0</td>\n",
       "      <td>10</td>\n",
       "      <td>00:00:00</td>\n",
       "      <td>8.0</td>\n",
       "      <td>10</td>\n",
       "      <td>00:00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>A14164800</td>\n",
       "      <td>SI</td>\n",
       "      <td>SR</td>\n",
       "      <td>86.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>00:00:00</td>\n",
       "      <td>45.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>00:00:00</td>\n",
       "      <td>44.0</td>\n",
       "      <td>...</td>\n",
       "      <td>00:00:00</td>\n",
       "      <td>6.0</td>\n",
       "      <td>10</td>\n",
       "      <td>00:04:51</td>\n",
       "      <td>6.0</td>\n",
       "      <td>10</td>\n",
       "      <td>00:00:00</td>\n",
       "      <td>7.0</td>\n",
       "      <td>10</td>\n",
       "      <td>00:00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>A14847419</td>\n",
       "      <td>TH</td>\n",
       "      <td>JR</td>\n",
       "      <td>100.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>00:00:00</td>\n",
       "      <td>100.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>00:00:00</td>\n",
       "      <td>78.0</td>\n",
       "      <td>...</td>\n",
       "      <td>00:00:00</td>\n",
       "      <td>10.0</td>\n",
       "      <td>10</td>\n",
       "      <td>00:00:00</td>\n",
       "      <td>10.0</td>\n",
       "      <td>10</td>\n",
       "      <td>00:00:00</td>\n",
       "      <td>10.0</td>\n",
       "      <td>10</td>\n",
       "      <td>00:00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>A14162943</td>\n",
       "      <td>SI</td>\n",
       "      <td>JR</td>\n",
       "      <td>66.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>00:00:00</td>\n",
       "      <td>33.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>00:00:00</td>\n",
       "      <td>42.0</td>\n",
       "      <td>...</td>\n",
       "      <td>00:00:00</td>\n",
       "      <td>5.0</td>\n",
       "      <td>10</td>\n",
       "      <td>00:00:00</td>\n",
       "      <td>5.0</td>\n",
       "      <td>10</td>\n",
       "      <td>00:00:00</td>\n",
       "      <td>6.0</td>\n",
       "      <td>10</td>\n",
       "      <td>00:00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>530</td>\n",
       "      <td>A14490387</td>\n",
       "      <td>SI</td>\n",
       "      <td>JR</td>\n",
       "      <td>100.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>47:26:10</td>\n",
       "      <td>82.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>00:00:00</td>\n",
       "      <td>78.0</td>\n",
       "      <td>...</td>\n",
       "      <td>00:00:00</td>\n",
       "      <td>10.0</td>\n",
       "      <td>10</td>\n",
       "      <td>12:08:58</td>\n",
       "      <td>10.0</td>\n",
       "      <td>10</td>\n",
       "      <td>00:00:00</td>\n",
       "      <td>10.0</td>\n",
       "      <td>10</td>\n",
       "      <td>00:00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>531</td>\n",
       "      <td>A14088257</td>\n",
       "      <td>SI</td>\n",
       "      <td>SO</td>\n",
       "      <td>100.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>00:00:00</td>\n",
       "      <td>86.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>00:00:00</td>\n",
       "      <td>72.0</td>\n",
       "      <td>...</td>\n",
       "      <td>00:00:00</td>\n",
       "      <td>9.0</td>\n",
       "      <td>10</td>\n",
       "      <td>00:00:00</td>\n",
       "      <td>10.0</td>\n",
       "      <td>10</td>\n",
       "      <td>00:00:00</td>\n",
       "      <td>10.0</td>\n",
       "      <td>10</td>\n",
       "      <td>00:00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>532</td>\n",
       "      <td>A14847419</td>\n",
       "      <td>WA</td>\n",
       "      <td>JR</td>\n",
       "      <td>87.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>00:00:00</td>\n",
       "      <td>90.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>00:00:00</td>\n",
       "      <td>66.0</td>\n",
       "      <td>...</td>\n",
       "      <td>00:00:00</td>\n",
       "      <td>9.0</td>\n",
       "      <td>10</td>\n",
       "      <td>00:00:00</td>\n",
       "      <td>9.0</td>\n",
       "      <td>10</td>\n",
       "      <td>00:00:00</td>\n",
       "      <td>9.0</td>\n",
       "      <td>10</td>\n",
       "      <td>00:00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>533</td>\n",
       "      <td>A14513929</td>\n",
       "      <td>TH</td>\n",
       "      <td>SR</td>\n",
       "      <td>84.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>00:00:00</td>\n",
       "      <td>83.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>00:00:00</td>\n",
       "      <td>62.0</td>\n",
       "      <td>...</td>\n",
       "      <td>00:00:00</td>\n",
       "      <td>9.0</td>\n",
       "      <td>10</td>\n",
       "      <td>00:00:00</td>\n",
       "      <td>9.0</td>\n",
       "      <td>10</td>\n",
       "      <td>419:06:41</td>\n",
       "      <td>8.0</td>\n",
       "      <td>10</td>\n",
       "      <td>00:00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>534</td>\n",
       "      <td>A14365863</td>\n",
       "      <td>WA</td>\n",
       "      <td>SR</td>\n",
       "      <td>90.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>00:00:00</td>\n",
       "      <td>75.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>00:00:00</td>\n",
       "      <td>78.0</td>\n",
       "      <td>...</td>\n",
       "      <td>21:47:10</td>\n",
       "      <td>10.0</td>\n",
       "      <td>10</td>\n",
       "      <td>00:00:00</td>\n",
       "      <td>10.0</td>\n",
       "      <td>10</td>\n",
       "      <td>00:00:00</td>\n",
       "      <td>10.0</td>\n",
       "      <td>10</td>\n",
       "      <td>00:00:00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>535 rows × 100 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           PID College Level  lab01  lab01 - Max Points  \\\n",
       "0    A14721419      SI    JR   99.0               100.0   \n",
       "1    A14883274      TH    JR   98.0               100.0   \n",
       "2    A14164800      SI    SR   86.0               100.0   \n",
       "3    A14847419      TH    JR  100.0               100.0   \n",
       "4    A14162943      SI    JR   66.0               100.0   \n",
       "..         ...     ...   ...    ...                 ...   \n",
       "530  A14490387      SI    JR  100.0               100.0   \n",
       "531  A14088257      SI    SO  100.0               100.0   \n",
       "532  A14847419      WA    JR   87.0               100.0   \n",
       "533  A14513929      TH    SR   84.0               100.0   \n",
       "534  A14365863      WA    SR   90.0               100.0   \n",
       "\n",
       "    lab01 - Lateness (H:M:S)  lab02  lab02 - Max Points  \\\n",
       "0                   00:00:00   86.0               100.0   \n",
       "1                   00:00:00   52.0               100.0   \n",
       "2                   00:00:00   45.0               100.0   \n",
       "3                   00:00:00  100.0               100.0   \n",
       "4                   00:00:00   33.0               100.0   \n",
       "..                       ...    ...                 ...   \n",
       "530                 47:26:10   82.0               100.0   \n",
       "531                 00:00:00   86.0               100.0   \n",
       "532                 00:00:00   90.0               100.0   \n",
       "533                 00:00:00   83.0               100.0   \n",
       "534                 00:00:00   75.0               100.0   \n",
       "\n",
       "    lab02 - Lateness (H:M:S)  project01  ...  discussion07 - Lateness (H:M:S)  \\\n",
       "0                   00:00:00       75.0  ...                         00:00:00   \n",
       "1                   00:00:00       53.0  ...                        669:12:21   \n",
       "2                   00:00:00       44.0  ...                         00:00:00   \n",
       "3                   00:00:00       78.0  ...                         00:00:00   \n",
       "4                   00:00:00       42.0  ...                         00:00:00   \n",
       "..                       ...        ...  ...                              ...   \n",
       "530                 00:00:00       78.0  ...                         00:00:00   \n",
       "531                 00:00:00       72.0  ...                         00:00:00   \n",
       "532                 00:00:00       66.0  ...                         00:00:00   \n",
       "533                 00:00:00       62.0  ...                         00:00:00   \n",
       "534                 00:00:00       78.0  ...                         21:47:10   \n",
       "\n",
       "    discussion08  discussion08 - Max Points  discussion08 - Lateness (H:M:S)  \\\n",
       "0           10.0                         10                         00:00:00   \n",
       "1            7.0                         10                         00:00:00   \n",
       "2            6.0                         10                         00:04:51   \n",
       "3           10.0                         10                         00:00:00   \n",
       "4            5.0                         10                         00:00:00   \n",
       "..           ...                        ...                              ...   \n",
       "530         10.0                         10                         12:08:58   \n",
       "531          9.0                         10                         00:00:00   \n",
       "532          9.0                         10                         00:00:00   \n",
       "533          9.0                         10                         00:00:00   \n",
       "534         10.0                         10                         00:00:00   \n",
       "\n",
       "    discussion09  discussion09 - Max Points  discussion09 - Lateness (H:M:S)  \\\n",
       "0           10.0                         10                        780:01:28   \n",
       "1            7.0                         10                         00:00:00   \n",
       "2            6.0                         10                         00:00:00   \n",
       "3           10.0                         10                         00:00:00   \n",
       "4            5.0                         10                         00:00:00   \n",
       "..           ...                        ...                              ...   \n",
       "530         10.0                         10                         00:00:00   \n",
       "531         10.0                         10                         00:00:00   \n",
       "532          9.0                         10                         00:00:00   \n",
       "533          9.0                         10                        419:06:41   \n",
       "534         10.0                         10                         00:00:00   \n",
       "\n",
       "    discussion10  discussion10 - Max Points  discussion10 - Lateness (H:M:S)  \n",
       "0           10.0                         10                         00:00:00  \n",
       "1            8.0                         10                         00:00:00  \n",
       "2            7.0                         10                         00:00:00  \n",
       "3           10.0                         10                         00:00:00  \n",
       "4            6.0                         10                         00:00:00  \n",
       "..           ...                        ...                              ...  \n",
       "530         10.0                         10                         00:00:00  \n",
       "531         10.0                         10                         00:00:00  \n",
       "532          9.0                         10                         00:00:00  \n",
       "533          8.0                         10                         00:00:00  \n",
       "534         10.0                         10                         00:00:00  \n",
       "\n",
       "[535 rows x 100 columns]"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def checkpoint_total(grades):\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Do Sophomores get better grades?\n",
    "\n",
    "**Question 8**\n",
    "\n",
    "You notice that students who are sophomores on average did better in the class (if you can't verify this, you should go back and check your work!). Is this difference significant, or just due to noise?\n",
    "\n",
    "Perform a hypothesis test, assessing likelihood of the null hypothesis: \n",
    "> \"sophomores earn grades that are roughly equal on average to the rest of the class.\"\n",
    "\n",
    "\n",
    "Create a function `simulate_pval` which takes in the number of simulations `N` and `grades` and returns the the likelihood that the grade of sophomores was no better on average than the class as a whole (i.e. calculate the p-value).\n",
    "\n",
    "*Note:* To check your work, plot the sampling distribution and the observation. Do these values look reasonable?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'total_grades' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-89-68ed2cfffa02>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0msophs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mgrades\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mgrades\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'Level'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m'SO'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mtotal_grades\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msophs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'total_grades' is not defined"
     ]
    }
   ],
   "source": [
    "sophs = grades[grades['Level'] == 'SO']\n",
    "total_grades(sophs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "fp = os.path.join('data', 'grades.csv')\n",
    "grades = pd.read_csv(fp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### What is the true distribution of grades?\n",
    "\n",
    "The gradebook for this class only reflects one particular instance of each student's performance, subject to the effects of all the little events and hiccups that occurred throughout the quarter. Might you have done better on the midterm had your roommate kept you up all night with their coughing? Wasn't it lucky that the example you were studying just before the final happened to appear on the exam?\n",
    "\n",
    "**Question 9**\n",
    "\n",
    "This question will simulate these '(un)lucky, random events' by adding or subtracting random amounts to each assignment before calculating the final grades. These 'random amounts' will be drawn from a Gaussian distribution of mean 0 and a std deviation 0.02:\n",
    "```\n",
    "np.random.normal(0, 0.02, size=(num_rows, num_cols))\n",
    "```\n",
    "Intuitively, such a model says that random events may bump up or down a given grade (given as a proportion):\n",
    "- which on average has no effect on the class as a whole (mean 0),\n",
    "- which not uncommonly might perturb a grade by 2% (std dev 0.02).\n",
    "\n",
    "Create a function `total_points_with_noise` that takes in a dataframe like `grades`, adds noise to the assignments as described above, and returns the final scores using *the same procedure* as questions 1-7.\n",
    "\n",
    "*Note:* You should be able to reuse (or minorly change) the code from previous problems. Try to be DRY (don't repeat yourself)!\n",
    "\n",
    "*Note 1:* Once adding the noise to the assignment scores, use the `np.clip` function to be sure each assignment retains a score between 0% and 100%.\n",
    "\n",
    "*Note 2:* To check your work -- what would you expect the difference between the actual scores and noisy scores to be, on average?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3      0.900989\n",
       "4      0.648927\n",
       "5      0.902117\n",
       "6      0.794718\n",
       "7      0.948493\n",
       "         ...   \n",
       "96     0.888833\n",
       "97     0.900596\n",
       "98     0.880979\n",
       "99     0.893520\n",
       "100    0.884403\n",
       "Length: 98, dtype: float64"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = get_prop_df(grades)\n",
    "\n",
    "for col in columns['projects']:\n",
    "    project_scores.append()\n",
    "\n",
    "project_scores = sum(df['project'/len(columns['project'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "#get dataframe with grade proportions for each assignment\n",
    "def get_prop_df(grades): \n",
    "    grades = grades.replace({np.nan: 0})\n",
    "\n",
    "    #get lab grades first\n",
    "    processed = process_labs(grades)\n",
    "    df = processed\n",
    "\n",
    "    names = get_assignment_names(grades)\n",
    "    #we already have lab grades\n",
    "    del names['lab']\n",
    "    cols = unwind(names)\n",
    "\n",
    "\n",
    "    for i in cols:\n",
    "        score = grades[i] / grades[i + ' - Max Points']\n",
    "        df[i] = score\n",
    "\n",
    "\n",
    "    return df\n",
    "\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "def unwind(columns):\n",
    "    columns.values()\n",
    "    cols = []\n",
    "    \n",
    "    for i in columns.values():\n",
    "        for j in i:\n",
    "            cols.append(j)\n",
    "            \n",
    "    return cols\n",
    "\n",
    "def total_points_with_noise(grades):\n",
    "    \"\"\"\n",
    "    total_points_with_noise takes in a dataframe like grades,\n",
    "    adds noise to the assignments as described in notebook, and returns\n",
    "    the total scores of each student calculated with noisy grades.\n",
    "\n",
    "    :Example:\n",
    "    >>> fp = os.path.join('data', 'grades.csv')\n",
    "    >>> grades = pd.read_csv(fp)\n",
    "    >>> out = total_points_with_noise(grades)\n",
    "    >>> np.all((0 <= out) & (out <= 1))\n",
    "    True\n",
    "    >>> 0.7 < out.mean() < 0.9\n",
    "    True\n",
    "    \"\"\"\n",
    "\n",
    "    props = get_prop_df(grades)\n",
    "    \n",
    "    num_rows = props.shape[0]\n",
    "    num_cols = props.shape[1]\n",
    "    random_amt = pd.DataFrame(np.random.normal(0, 0.02, size=(num_rows, num_cols)))\n",
    "    \n",
    "    \n",
    "    noise = get_prop_df(grades).copy()\n",
    "    columns = get_assignment_names(grades)\n",
    "    n = 0\n",
    "    \n",
    "    for col in unwind(columns):\n",
    "        noise[col] = np.clip(noise[col] + random_amt[n], 0, 100)\n",
    "        n += 1\n",
    "        \n",
    "        \n",
    "    #total grade calculation for noise\n",
    "    #lab total\n",
    "    lab_scores = lab_total(props)\n",
    "    \n",
    "    # project total\n",
    "    project_scores = []\n",
    "    for col in columns['project']:\n",
    "        project_scores.append(noise[col])\n",
    "    project_total = sum(project_scores)/len(columns['project'])\n",
    "    \n",
    "    # checkpoint total\n",
    "    chk_scores = []\n",
    "    for col in columns['checkpoint']:\n",
    "        chk_scores.append(noise[col])\n",
    "    chk_total = sum(chk_scores)/len(columns['checkpoint'])\n",
    "\n",
    "    # discussion total\n",
    "    disc_scores = []\n",
    "    for col in columns['disc']:\n",
    "        disc_scores.append(noise[col])\n",
    "    disc_total = sum(disc_scores)/len(columns['disc'])\n",
    "    \n",
    "    #midterm and final\n",
    "    midterm_total = noise['Midterm']\n",
    "    final_total = noise['Final']\n",
    "    \n",
    "    \n",
    "    return (lab_scores * 0.2) + (project_total * 0.3) + (chk_total * 0.025) + (disc_total * 0.025) + (midterm_total * 0.15) + (final_total * 0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fp = os.path.join('data', 'grades.csv')\n",
    "grades = pd.read_csv(fp)\n",
    "out = total_points_with_noise(grades)\n",
    "#np.all((0 <= out) & (out <= 1))\n",
    "\n",
    "0.7 < out.mean() < 0.9\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(get_assignment_names(grades))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Short-answer questions (hard-coded)\n",
    "\n",
    "Use your functions from above to understanding the data and answer the following questions. The function below should return **hard-coded values**. It should not compute anything!\n",
    "\n",
    "**Question 10**\n",
    "\n",
    "Create a function `short_answer` of zero variables that returns (hard-coded) answers to the following question in a list:\n",
    "0. For the class on average, what is the difference between students' scores (`total_points`) and their scores with noise (`total_points_with_noise`)? (Remark: plot the distribution of differences; does this align with what you know about binomial distributions?)\n",
    "1. What percentage of the class only sees their grade change at most (but not including) $\\pm 0.01$?\n",
    "2. What is the 95% confidence interval for the statistic above? (see [DSC10](https://www.inferentialthinking.com/chapters/13/3/Confidence_Intervals.html) and use `np.percentile`)\n",
    "3. What proportion of the class sees a change in their letter grade?\n",
    "4. The assumption behind the model in Question 9 is that:\n",
    "    - The (observed) gradebook well represents the true population of students,\n",
    "    - The noisy scores represent other possible observations drawn from the true population of students.\n",
    "    - Answer `True` or `False`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Congratulations, you finished the project!\n",
    "\n",
    "### Before you submit:\n",
    "* Be sure you run the doctests on all your code in project01.py\n",
    "\n",
    "### To submit:\n",
    "* **Upload the .py file to gradescope**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
